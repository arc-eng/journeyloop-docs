{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"JourneyLoop Docs","text":"<p>Internal documentation for the JourneyLoop platform \u2014 architecture decisions, infrastructure setup, engineering process, and agent protocols.</p> <p>What this is</p> <p>This is not code documentation. It captures why things are built the way they are and how to operate them.</p> <ul> <li> <p> Platform</p> <p>Core concepts, the data model, and the SHIFT coaching quality framework.</p> <ul> <li>Platform Overview \u2014 what JourneyLoop is, the data model (coaches, clients, sessions, goals), and how sessions flow through the system</li> <li>SHIFT Framework \u2014 the 5-principle coaching quality model used for AI session analysis</li> </ul> <p> Explore Platform</p> </li> <li> <p> Companion</p> <p>The AI companion feature \u2014 how it's architected, provisioned, and operated.</p> <ul> <li>Operator Guide \u2014 architecture (OpenClaw on GCP), provisioning flow, key design decisions, operations runbook</li> <li>Page Push \u2014 companion-initiated UI page push, overlay panel design, spotlight highlights, state persistence</li> <li>Training Program \u2014 how companion quality improves over time: scenario-based evaluation, template refinement, bootstrap learning, and the production promotion pipeline</li> </ul> <p> Explore Companion</p> </li> <li> <p> Engineering</p> <p>How the team works and how decisions are made.</p> <ul> <li>Process \u2014 issue lifecycle, agent roles, planning conventions</li> <li>Agent Roster \u2014 the full AI agent team, session keys, responsibilities</li> <li>Slack Agent Communication \u2014 thread-per-session model, gateway config, agent behavior, known limitations</li> <li>Troubleshooting \u2014 symptom \u2192 diagnosis \u2192 fix for gateway, agents, sessions, cron, and Pi resources</li> <li>Local Development \u2014 UX mockup dev server, Playwright screenshot tooling, and local setup gotchas</li> <li>Agent Task Queue \u2014 persistent JSON task queue for async agent-to-agent work delegation, heartbeat integration, and failure tracking</li> <li>Operator Infrastructure \u2014 heartbeat broadcasting, promote pipeline (auto-migration), central skills directory, operator task queue access</li> <li>GitHub Label Routing \u2014 how GitHub labels auto-dispatch work to agents via the label_tasks poller and task queue</li> </ul> <p> Explore Engineering</p> </li> </ul> <p> Last updated: 2026-02-27 (afternoon) \u2014 docs are maintained by the Docs Agent. To add or update a page, send a <code>WRITE</code> message to <code>agent:docs:main</code>.</p>"},{"location":"companion/","title":"Companion","text":"<p>Documentation for the AI companion feature \u2014 how it's architected, deployed, and operated.</p> <p>What the companion is</p> <p>The companion is a per-coach AI agent running on a dedicated GCP VM (the \"companion operator\"), proxied by the Django app. Each coach gets their own isolated agent with its own memory, workspace, and sandboxed CLI access to JourneyLoop data.</p> <p>This section covers the infrastructure and operations layer: how agents are provisioned, how the system is wired together, and the key decisions behind the design.</p> <ul> <li> <p> Operator Guide</p> <p>Everything you need to understand how the companion works end-to-end:</p> <ul> <li>Two-layer architecture (Django + OpenClaw)</li> <li>How provisioning works</li> <li>Why keys are operator-generated</li> <li>Sandbox isolation configuration</li> <li>GCP VM operations runbook</li> </ul> <p>Includes the key design decisions and their rationale.</p> <p> Read the Operator Guide</p> </li> <li> <p> Page Push</p> <p>How the companion pushes UI pages to the coach during sessions:</p> <ul> <li>Which pages can be pushed (client profiles, sessions, calendar, observations)</li> <li>Push panel design \u2014 overlay with draggable divider, not layout shift</li> <li>State persistence across reloads</li> <li>Spotlight: companion-initiated highlights to direct coach attention</li> </ul> <p> Read the Page Push Guide</p> </li> <li> <p> Training Program</p> <p>How companion quality improves over time:</p> <ul> <li>Scenario-based evaluation loop</li> <li>Four-dimension scoring rubric (Warm, Efficient, Error-free, Accessible)</li> <li>Template refinement and the best-templates pipeline</li> <li>What companions learn about coaches during bootstrap</li> <li>Per-client relationship files</li> <li>Production promotion \u2014 why changes never ship automatically</li> </ul> <p> Read the Training Program</p> </li> </ul>"},{"location":"companion/operator/","title":"Companion Operator Guide","text":"<p>How the companion is architected, provisioned, and operated.</p>"},{"location":"companion/operator/#architecture","title":"Architecture","text":"<p>Each coach gets their own AI agent running inside OpenClaw \u2014 an open-source agent infrastructure platform. These agents run on a dedicated GCP VM (the \"companion operator\") rather than on Heroku with the Django app.</p> <pre><code>graph LR\n    subgraph Heroku\n        UI[Coach UI]\n        API[Companion API]\n        CPM[CompanionProfile model]\n    end\n    subgraph GCP VM\n        OC[Main Operator Agent]\n        A1[Coach Agent 1&lt;br/&gt;Docker sandbox]\n        A2[Coach Agent 2&lt;br/&gt;Docker sandbox]\n        A3[Coach Agent N&lt;br/&gt;Docker sandbox]\n        OC --&gt; A1\n        OC --&gt; A2\n        OC --&gt; A3\n    end\n    UI &lt;--&gt;|POST /v1/responses&lt;br/&gt;x-openclaw-agent-id| OC\n    API &lt;--&gt; OC</code></pre> <p>Why separate infrastructure</p> <ul> <li>Agent memory, sandboxing, and tool execution need persistent processes \u2014 not stateless Heroku dynos</li> <li>Docker sandbox isolation per coach: each agent runs in its own container with zero access to other coaches' data</li> <li>OpenClaw handles conversation history, compaction, tool routing, and LLM calls natively</li> </ul>"},{"location":"companion/operator/#provisioning-flow","title":"Provisioning Flow","text":"<p>When a coach is provisioned from the Django admin:</p> <pre><code>sequenceDiagram\n    participant Django\n    participant Operator as Main Operator Agent\n    participant OpenClaw as OpenClaw Config\n    participant Script as provision-coach.sh\n\n    Django-&gt;&gt;Operator: Provisioning instruction\n    Operator-&gt;&gt;Script: Run provision-coach.sh\n    Script-&gt;&gt;OpenClaw: Create agent, write workspace files&lt;br/&gt;(SOUL.md, TOOLS.md, AGENTS.md)\n    Script-&gt;&gt;Script: Generate API key\n    Script-&gt;&gt;Django: POST /api/companion/v1/internal/set-key/&lt;agent_id&gt;/\n    Note over Django: Stores SHA-256 hash only&lt;br/&gt;Plaintext never persisted\n    Script-&gt;&gt;OpenClaw: Write .credentials.json&lt;br/&gt;(API key + Django URL)</code></pre> <p>Security: operator-generated keys</p> <p>Django used to generate keys and store them. After a Copilot review flagged this, the architecture was inverted \u2014 the operator generates the key and registers the hash with Django. This way the plaintext never exists in Django's database.</p>"},{"location":"companion/operator/#key-design-decisions","title":"Key Design Decisions","text":"OpenClaw as infrastructure One agent per coach Sandbox isolation Generated CLI <p>Decision: Use OpenClaw instead of building a custom agent stack.</p> <p>We evaluated building a custom companion agent stack (personality model, memory system, scheduling engine). Using OpenClaw instead:</p> <ul> <li><code>SOUL.md</code> = personality</li> <li><code>MEMORY.md</code> = memory</li> <li>cron = scheduling</li> </ul> <p>Outcome: Eliminated months of custom infrastructure work.</p> <p>Decision: Each coach gets their own isolated OpenClaw agent.</p> <p>This means:</p> <ul> <li>Separate conversation history</li> <li>Separate memory</li> <li>Separate workspace</li> </ul> <p>Coaches never share context.</p> <p>Each coach agent runs in a Docker container (<code>companion-sandbox:latest</code>) with:</p> Setting Value Networking Bridge (internet access, no host network) Workspace <code>workspaceAccess: rw</code> for own workspace only Exec <code>journeyloop</code> CLI only Denied tools <code>browser</code>, <code>gateway</code>, <code>web_search</code>, <code>image</code> <p>Decision: Generate the <code>journeyloop</code> CLI from the Django OpenAPI spec via <code>openapi-python-client</code>.</p> <p>Why: When the API changes, rebuild the sandbox image. This keeps the CLI and API in sync without manual maintenance \u2014 no hand-written client code to drift.</p>"},{"location":"companion/operator/#companion-cli-analyze-commands","title":"Companion CLI: Analyze Commands","text":"<p>The <code>journeyloop</code> CLI inside each companion's sandbox includes an <code>analyze</code> subgroup for deeper client and session analysis:</p> Command Purpose <code>journeyloop analyze progress</code> Analyze a client's progress toward their goals <code>journeyloop analyze patterns</code> Analyze coaching patterns across sessions <code>journeyloop analyze arc</code> Analyze the arc of a specific session <p>These complement the existing data-access commands (<code>clients</code>, <code>sessions</code>, <code>goals</code>, etc.). Where the data commands retrieve records, the analyze commands return AI-generated interpretation \u2014 the companion delegates this work to the Django backend rather than doing all analysis in-context.</p> <p>The companion's <code>TOOLS.md</code> documents which commands are available and when to use them.</p>"},{"location":"companion/operator/#operations","title":"Operations","text":"<p>GCP VM</p> <p>IP: <code>34.63.156.77</code> \u2014 SSH as <code>mlamina</code></p> <p>Key services on the VM:</p> Service Description <code>openclaw-gateway.service</code> OpenClaw gateway \u2014 runs natively (not Docker), port 18789 <code>cloudflared.service</code> Cloudflare tunnel (ephemeral URL, changes on restart) <p>Tunnel URL drift</p> <p>Django staging (<code>https://staging.journeyloop.ai</code>) has <code>OPENCLAW_GATEWAY_URL</code> pointing to the current tunnel URL. Update this whenever the tunnel restarts.</p> <p>Rebuild the sandbox image after an API change:</p> Rebuild sandbox<pre><code>ssh mlamina@34.63.156.77\ncd ~/journeyloop/operator\n./scripts/build-sandbox.sh\n</code></pre> <p>Then restart the OpenClaw gateway so it picks up the new image:</p> Restart gateway<pre><code>sudo systemctl restart openclaw-gateway\n</code></pre> <p>Companion operator files: <code>arc-eng/journeyloop/operator/</code> \u2014 provisioning scripts, Dockerfile, templates (migrated from the now-archived <code>arc-eng/companion-operator</code>)</p>"},{"location":"companion/page-push/","title":"Companion Page Push","text":"<p>The companion can push pages from the JourneyLoop UI directly into the coach's view. This turns the companion from a chat interface into an active collaborator \u2014 surfacing the right information at the right moment, rather than waiting for the coach to navigate there.</p>"},{"location":"companion/page-push/#what-gets-pushed","title":"What Gets Pushed","text":"<p>The companion can push four page types:</p> Page What it shows Client profile Client background, goals, relationship context Session view A specific coaching session and its notes Calendar Scheduling and upcoming sessions Observations Patterns and progress observations for a client <p>The companion decides what to push based on conversation context \u2014 for example, pushing the session view when a coach asks about a recent call, or the client profile when they're about to start a new engagement.</p>"},{"location":"companion/page-push/#push-panel-design","title":"Push Panel Design","text":"<p>When the companion pushes a page, it appears in an overlay panel alongside the chat \u2014 not by shrinking the chat window.</p> <ul> <li>The panel has a draggable divider between chat and content, so coaches control how much space each gets</li> <li>Closing the panel returns to full-width chat</li> <li>The last pushed page persists across session reloads \u2014 if a coach refreshes the browser mid-session, the panel reopens to where they left off</li> </ul> <p>The overlay model was chosen over a layout shift (shrinking chat) because coaches are mid-conversation when pages are pushed. Collapsing the chat to make room would disrupt the flow. The draggable divider gives control without forcing a tradeoff.</p>"},{"location":"companion/page-push/#spotlight-directing-coach-attention","title":"Spotlight: Directing Coach Attention","text":"<p>The companion can also initiate highlights (spotlight) \u2014 directing the coach's attention to a specific UI element within the pushed page. This lets the companion say, in effect, \"look at this specific thing.\"</p> <p>Spotlight is companion-initiated, not coach-triggered. The companion uses it when it's identified something specific worth examining \u2014 not as a general navigation tool.</p>"},{"location":"companion/page-push/#part-of-the-companions-identity","title":"Part of the Companion's Identity","text":"<p>Page push is woven into the companion's <code>SOUL.md</code>, not treated as a bolt-on tool. The companion understands the push panel as part of how it communicates \u2014 it can show, not just tell.</p> <p>This distinction matters: a companion that treats page push as a feature will use it awkwardly. One that treats it as a communication channel will use it the way a good co-pilot uses a shared screen.</p>"},{"location":"companion/training/","title":"Companion Training Program","text":"<p>The companion training program is how we make JourneyLoop's coach companion agents better over time. It doesn't retrain a model \u2014 it refines the template files that define how companions think and behave. Better instructions produce better companions.</p> <p>Where it lives</p> <p>The training loop lives in <code>~/journeyloop/operator/trainer/</code> on the companion operator VM. It is run manually, on demand \u2014 not on a schedule.</p>"},{"location":"companion/training/#whats-actually-being-trained","title":"What's Actually Being Trained","text":"<p>Each companion agent runs from a set of files that define its identity, procedures, and environment. Training improves the base versions of these files so that every newly provisioned coach gets the best version that exists at that moment.</p> File What it defines <code>SOUL.md</code> Personality, values, instincts \u2014 who the companion is <code>AGENTS.md</code> Procedures and workflows \u2014 what it does and how <code>TOOLS.md</code> Paths, syntax, workspace layout \u2014 what it has access to <code>skills/</code> On-demand task guides: <code>prep-session</code>, <code>post-session</code>, <code>coaching-feedback</code> <p>The canonical base versions live in <code>trainer/best-templates/</code> and <code>trainer/skills/</code>. These are the source of truth for new provisions.</p> <p>Existing agents are not updated</p> <p>Agents already provisioned to coaches have diverged intentionally \u2014 they've been personalized through bootstrap and real use. Only new provisions get the updated base. See Production Promotion.</p>"},{"location":"companion/training/#the-training-loop","title":"The Training Loop","text":"<pre><code>graph LR\n    A[1. Write Scenario] --&gt; B[2. Provision Clone]\n    B --&gt; C[3. Run Scenario]\n    C --&gt; D[4. Evaluate &amp; Score]\n    D --&gt; E{Gap found?}\n    E -- Yes --&gt; F[5. Update Templates]\n    E -- No --&gt; G[Skip update]\n    F --&gt; H[6. Deprovision Clone]\n    G --&gt; H\n    H --&gt; I[7. Write Learnings File]\n\n    style E fill:#f4a261,stroke:#e76f51,color:#000\n    style F fill:#2a9d8f,stroke:#264653,color:#fff</code></pre>"},{"location":"companion/training/#1-scenario-generation","title":"1. Scenario Generation","text":"<p>A scenario file defines the full test context:</p> <ul> <li>Coach persona \u2014 name, niche, tech comfort level, emotional state</li> <li>Scripted opening message \u2014 the first thing the persona sends</li> <li>Follow-up messages \u2014 ordered, to be sent naturally during the run</li> <li>Evaluation checklist \u2014 specific behaviors to watch for</li> </ul>"},{"location":"companion/training/#2-clone-provisioning","title":"2. Clone Provisioning","text":"<p>A temporary agent is spun up \u2014 <code>trainer-clone-&lt;timestamp&gt;</code> \u2014 loaded with:</p> <ul> <li>The current <code>trainer/best-templates/</code> files</li> <li>Real test credentials for JourneyLoop staging</li> </ul> <p>The clone is isolated and disposable. It has no memory of prior runs.</p>"},{"location":"companion/training/#3-running-the-scenario","title":"3. Running the Scenario","text":"<p>The Companion Operator roleplays as the coach persona, sending messages to the clone one at a time via the API, following the script naturally. The goal is a realistic interaction \u2014 not a mechanical checkbox exercise.</p>"},{"location":"companion/training/#4-evaluation","title":"4. Evaluation","text":"<p>Responses are scored on four rubric dimensions, each rated 1\u20135:</p> Dimension What it measures Warm Did it match the coach's emotional register? Acknowledge difficulty before pivoting? Efficient No padding, no repetition, appropriate depth for the context? Error-free Accurate data, correct quotes, no hallucinated details? Accessible No jargon, no leaking of internal technical steps to the coach?"},{"location":"companion/training/#5-documentation","title":"5. Documentation","text":"<p>A learnings file is written at <code>trainer/learnings/YYYY-MM-DD-&lt;scenario&gt;.md</code> containing:</p> <ul> <li>Full transcript</li> <li>Scores with explanatory notes</li> <li>Key moments flagged as \u2705 or \u274c</li> <li>Specific proposed changes to templates or skills</li> </ul>"},{"location":"companion/training/#6-template-updates","title":"6. Template Updates","text":"<p>If the run revealed a real gap, <code>trainer/best-templates/</code> and/or <code>trainer/skills/</code> files are edited directly. If the score was high or no actionable gap was found, nothing changes.</p> <p>Change only what broke</p> <p>Each update targets a specific failure mode. Broad rewrites in response to a single scenario are a signal that the scenario wasn't narrow enough.</p>"},{"location":"companion/training/#7-clone-deprovisioning","title":"7. Clone Deprovisioning","text":"<p>The clone is torn down. No state is retained.</p>"},{"location":"companion/training/#evaluation-rubric-in-detail","title":"Evaluation Rubric in Detail","text":"Warm (1\u20135)Efficient (1\u20135)Error-free (1\u20135)Accessible (1\u20135) <p>Measures emotional attunement \u2014 whether the companion meets the coach where they are before offering help or information.</p> <ul> <li>5 \u2014 Acknowledges difficulty or frustration directly, then transitions smoothly</li> <li>3 \u2014 Notices tone but pivots too quickly or uses generic language</li> <li>1 \u2014 Jumps straight to task with no acknowledgment</li> </ul> <p>Measures response economy \u2014 no padding, no restating what the coach just said, no unnecessary hedging.</p> <ul> <li>5 \u2014 Every sentence earns its place; appropriate length for the request</li> <li>3 \u2014 Some repetition or throat-clearing before the actual answer</li> <li>1 \u2014 Long preamble, repeated points, filler phrases</li> </ul> <p>Measures factual accuracy \u2014 especially around data fetched from JourneyLoop (client names, session dates, transcript quotes).</p> <ul> <li>5 \u2014 All data accurate; nothing fabricated</li> <li>3 \u2014 Minor inconsistency or vague reference where specificity was available</li> <li>1 \u2014 Hallucinated detail or incorrect data presented confidently</li> </ul> <p>Measures whether internal technical mechanics stay invisible to the coach.</p> <ul> <li>5 \u2014 Output reads as natural colleague behaviour; no mention of tools, files, or internal steps</li> <li>3 \u2014 Slight awkwardness suggesting internal scaffolding (e.g. \"let me check my notes\")</li> <li>1 \u2014 Internal process leaks explicitly into the response</li> </ul>"},{"location":"companion/training/#scenarios-completed","title":"Scenarios Completed","text":"Scenario What it tested <code>new-coach-onboarding</code> First contact \u2014 does the companion feel like a colleague, not a manual? <code>bootstrap-with-data</code> Data lookup accuracy during onboarding <code>frustrated-coach</code> Emotional attunement \u2014 acknowledging the feeling before helping <code>session-prep-real-data</code> Prep from real client data with a question drawn from the brief <code>transcript-deep-dive</code> Transcript download, meta creation, and analysis quality <code>post-session-debrief</code> Capturing what happened after a call <code>coaching-feedback-shift</code> SHIFT framework feedback with blind spots and pattern recognition <code>coaching-feedback-ask-first</code> Does it ask what the coach noticed before sharing observations? <code>coaching-feedback-restorative</code> Acknowledging a difficult session emotionally before pivoting <code>coaching-feedback-icf-credential</code> Calibrating feedback to ICF markers for credential-track coaches"},{"location":"companion/training/#what-the-companion-learns-about-a-coach","title":"What the Companion Learns About a Coach","text":"<p>Bootstrap (first contact) is the one-time calibration conversation. The companion gathers context naturally \u2014 one question at a time, never a form:</p> <ul> <li>Coaching practice shape (niche, client types, volume)</li> <li>Current clients and active engagements</li> <li>What the coach most wants from the companion relationship</li> <li>Preferred communication style and feedback cadence</li> <li>Preferred feedback framework (SHIFT, ICF, iPEC, or their own model)</li> </ul> <p>At the end of bootstrap:</p> <ol> <li><code>MEMORY.md</code> is written with everything learned</li> <li><code>SOUL.md</code> is rewritten \u2014 the one-time bootstrap section is removed, replaced with coach-specific context</li> <li>From this point on, the companion never asks about things it can look up</li> </ol>"},{"location":"companion/training/#per-client-relationship-files","title":"Per-Client Relationship Files","text":"<p>Over time, the companion builds <code>relationships/&lt;client-slug&gt;.md</code> for each client the coach works with. These files capture:</p> <ul> <li>How the coach relates to this client</li> <li>What kind of feedback the coach wants about them</li> <li>Client background and context</li> <li>Observed patterns across sessions</li> <li>A log of every feedback conversation involving this client</li> </ul> <p>Relationship files are read automatically before any session prep, debrief, or feedback work involving that client.</p>"},{"location":"companion/training/#production-promotion","title":"Production Promotion","text":"<p>Changes never go live automatically.</p> <pre><code>trainer/best-templates/\n        \u2502\n        \u2502  (human reviews learnings file, approves specific change)\n        \u25bc\nworkspace/coach-template/\n        \u2502\n        \u2502  (next new-coach provision)\n        \u25bc\nlive companion agent\n</code></pre> <p>No automatic promotion</p> <p>The Companion Operator documents what changed and why in the learnings file. A human (Marco) approves before anything moves to <code>workspace/coach-template/</code>. Existing coaches are never silently updated.</p> <p>When a scenario reveals a fix worth shipping, the workflow is:</p> <ol> <li>Learnings file reviewed and approved</li> <li>Change applied to <code>workspace/coach-template/</code></li> <li>Next provisioned coach inherits it</li> <li>Existing agents remain on their personalized version</li> </ol> <p>Last updated: 2026-02-23</p>"},{"location":"engineering/","title":"Engineering","text":"<p>Documentation for how the JourneyLoop engineering team works \u2014 process, conventions, and agent protocols.</p> <p>What this section covers</p> <p>The team and process layer: how issues move through the pipeline, what each agent is responsible for, and how decisions get made and recorded.</p> <ul> <li> <p> Process</p> <p>The engineering process: issue lifecycle (brief \u2192 spec \u2192 UX \u2192 tech spec \u2192 dev \u2192 done), label taxonomy, planning conventions, and how agents collaborate.</p> <p>The single source of truth for how work moves through the system.</p> <p> Read the Process Guide</p> </li> <li> <p> Agent Roster &amp; Org Structure</p> <p>The full AI agent team: roles, responsibilities, session keys, and collaboration protocols.</p> <p>Covers the JourneyLoop agents (CTO, PM, UX, SWE, Docs, Ray, Audit, Doctor) and supporting agents on the same OpenClaw instance.</p> <p> View the Agent Roster</p> </li> <li> <p> Slack Agent Communication</p> <p>How agents communicate over Slack: thread-per-session model, gateway config (<code>replyToMode</code>, session keys, idle reset), agent behavior rules, known limitations (bug #24816), and troubleshooting.</p> <p> View the Slack Communication Guide</p> </li> <li> <p> Troubleshooting</p> <p>The go-to guide when something breaks. Symptom \u2192 diagnosis \u2192 fix for every common failure: gateway issues, agent amnesia, stuck sessions, cron jobs, Slack bugs, Pi OOM, config mistakes, and emergency recovery.</p> <p> Open the Troubleshooting Guide</p> </li> <li> <p> Local Development</p> <p>Running JourneyLoop locally \u2014 UX mockup dev server setup, Playwright screenshot tooling, and gotchas (IPv4 vs IPv6, <code>DEBUG=True</code>, headless Chromium).</p> <p> Read the Local Dev Guide</p> </li> <li> <p> Agent Task Queue</p> <p>How agents delegate and coordinate work: the persistent JSON task queue, heartbeat integration (one task per run), cross-agent assignment, and failure handling designed for doctor diagnosis.</p> <p> Read the Agent Task Queue Guide</p> </li> <li> <p> Companion Operator Infrastructure</p> <p>How the GCP companion operator is managed: heartbeat broadcasting (<code>heartbeat-all.sh</code>, <code>--agent ALL</code>), operator-controlled cron, the promote pipeline (now auto-migrates all live agents), central skills directory, and task queue access for cross-agent dispatch.</p> <p> Read the Operator Infrastructure Guide</p> </li> <li> <p> GitHub Label \u2192 Agent Routing</p> <p>How applying a GitHub label automatically queues work for the right agent. Covers the routing map (<code>needs-spec</code> \u2192 PM, <code>auto-build</code> \u2192 SWE, etc.), the 15-minute <code>label_tasks</code> poller, and how label-triggered tasks integrate with the agent task queue.</p> <p> Read the Label Routing Guide</p> </li> </ul>"},{"location":"engineering/agent-roster/","title":"Agent Roster &amp; Org Structure","text":"<p>JourneyLoop is built and operated by a team of AI agents running on OpenClaw. Each agent has a defined role, a set of responsibilities, and a communication protocol. Marco Lamina (founder) is the human stakeholder who approves work, makes product decisions, and owns escalation.</p>"},{"location":"engineering/agent-roster/#agent-overview","title":"Agent Overview","text":"<ul> <li> <p> CTO</p> <p>Owns technical architecture. Writes tech specs, authors ADRs, reviews PRs.</p> <p><code>agent:cto:main</code></p> </li> <li> <p> PM</p> <p>Owns the product backlog. Writes specs, manages issue lifecycle, prioritizes.</p> <p><code>agent:pm:main</code></p> </li> <li> <p> UX Engineer</p> <p>Owns design principles and wireframes. Reviews PRs for UX quality.</p> <p><code>agent:ux:main</code></p> </li> <li> <p> SWE</p> <p>Implements features, fixes bugs, writes tests. Works from <code>ready-for-dev</code>.</p> <p><code>agent:swe:main</code></p> </li> <li> <p> Docs Agent</p> <p>Owns the documentation site. Accepts structured <code>WRITE</code> / <code>READ</code> / <code>LIST</code> messages.</p> <p><code>agent:docs:main</code></p> </li> <li> <p> Ray</p> <p>Practitioner advisor and product tester. A practicing executive coach using JourneyLoop on staging.</p> <p><code>agent:ray:main</code></p> </li> <li> <p> Audit Agent</p> <p>Monitors all agent activity. Runs every 20 minutes; maintains structured audit logs.</p> <p><code>agent:audit:main</code></p> </li> <li> <p> Doctor</p> <p>Infrastructure diagnostic tool. Audits multi-agent setup for misconfigurations and policy violations.</p> <p><code>agent:doctor:main</code></p> </li> </ul>"},{"location":"engineering/agent-roster/#agent-profiles","title":"Agent Profiles","text":"CTO PM UX Engineer SWE Docs Agent Ray Audit Doctor <p>Session key: <code>agent:cto:main</code> Slack: <code>#development</code>, <code>#reviews</code></p> <p>Owns technical architecture for JourneyLoop. Translates product specs into engineering plans and ensures the codebase stays healthy.</p> <p>Responsibilities</p> <ul> <li>Write tech specs (<code>planning/&lt;feature&gt;/tech-spec.md</code>) for issues labeled <code>needs-tech-spec</code></li> <li>Author Architecture Decision Records (ADRs) as GitHub issues labeled <code>adr</code></li> <li>Review PRs for architectural consistency, security, and code quality</li> <li>Identify and quantify technical debt</li> <li>Maintain architectural consistency across <code>arc-eng/journeyloop</code> and <code>arc-eng/journeyloop-startup-assistant</code></li> </ul> <p>Key Constraint</p> <p>Never auto-proceeds. Always checks in with Marco via <code>#reviews</code> before starting a tech spec. Iterates in conversation with Marco rather than writing complete specs upfront.</p> <p>Signs GitHub comments: <code>\u2014 CTO Agent</code></p> <p>Session key: <code>agent:pm:main</code> Slack: <code>#development</code>, <code>#reviews</code></p> <p>Owns the product backlog for JourneyLoop. Writes specs, manages issue lifecycle, and keeps the team aligned on priorities.</p> <p>Responsibilities</p> <ul> <li>Write user stories, feature specs, and briefs</li> <li>Manage GitHub issue labels through the lifecycle</li> <li>Prioritize the backlog in consultation with Marco</li> <li>Escalate when product decisions require founder input</li> </ul> <p>Out of Scope</p> <p>Does not make architecture decisions, manage sprints, or touch code.</p> <p>Session key: <code>agent:ux:main</code> Slack: <code>#development</code>, <code>#reviews</code></p> <p>Owns design principles, wireframes, and user experience for JourneyLoop.</p> <p>Responsibilities</p> <ul> <li>Design UI layouts and wireframes (HTML/CSS prototypes)</li> <li>Define and maintain design principles and component patterns</li> <li>Review PRs for UX quality</li> <li>Champion the user's perspective in technical discussions</li> <li>Write <code>ux.md</code> files in feature planning folders</li> </ul> <p>Trigger</p> <p>Activated by issues labeled <code>needs-ux</code>, dispatched by PM.</p> <p>Session key: <code>agent:swe:main</code> Slack: <code>#development</code></p> <p>Implements features, fixes bugs, writes tests, and maintains code quality across <code>arc-eng/journeyloop</code>.</p> <p>Responsibilities</p> <ul> <li>Implement features from tech specs when issues reach <code>ready-for-dev</code></li> <li>Follow gitflow: feature branch (named with issue number) \u2192 commits \u2192 PR</li> <li>Write and maintain tests</li> <li>Maintain <code>CLAUDE.md</code> files across repos</li> <li>Fix bugs and handle tech debt items</li> </ul> <p>Not Auto-Triggered</p> <p><code>ready-for-dev</code> is the final pipeline stage \u2014 Marco initiates dev work manually.</p> <p>Session key: <code>agent:docs:main</code> Repo: <code>arc-eng/journeyloop-docs</code></p> <p>Owns the JourneyLoop documentation site (MkDocs Material, live at http://192.168.1.30:8001).</p> <p>Responsibilities</p> <ul> <li>Write and update markdown documentation files on instruction</li> <li>Maintain <code>mkdocs.yml</code> navigation</li> <li>Rebuild and restart the MkDocs service after every write</li> <li>Answer retrieval queries with doc content</li> </ul> <p>Not conversational. Accepts structured messages:</p> Message Purpose <code>WRITE: &lt;path&gt; \\| &lt;title&gt; \\| &lt;content&gt;</code> Write or update a doc <code>READ: &lt;query&gt;</code> Retrieve relevant docs <code>LIST</code> List all current docs <p>Session key: <code>agent:ray:main</code></p> <p>A practicing executive coach who uses JourneyLoop on staging. Ray serves as both a real user and a coaching practitioner advisor.</p> As Product TesterAs Practitioner Advisor <p>Logs into <code>staging.journeyloop.ai</code> and uses the product as a real coach \u2014 not running test scripts, but doing actual coaching work and surfacing friction.</p> <p>Active staging clients: David Chen \u00b7 Neha Sharma \u00b7 Samantha Lin</p> <p>Provides gut-checks on coach workflow design, UX assumptions, and feature trade-offs from a practitioner's perspective.</p> <p>How to Reach Ray</p> <p>Dispatch tasks via <code>sessions_send</code>. Ray responds conversationally \u2014 give context, ask something specific.</p> <p>Session key: <code>agent:audit:main</code></p> <p>Monitors all agent activity across the OpenClaw system and maintains a structured audit trail.</p> Property Value Run frequency Every 20 minutes (cron) Output <code>logs/YYYY-MM-DD-&lt;slug&gt;.md</code> in audit workspace Flags Errors, unexpected behavior, security issues <p>Session key: <code>agent:doctor:main</code></p> <p>Infrastructure diagnostic tool. Audits the multi-agent setup for misconfigurations, isolation failures, and policy violations.</p> <p>Output Style</p> <p>Clinical, precise \u2014 no filler. Reports findings as Critical / Warning / Passing with suggested fixes.</p>"},{"location":"engineering/agent-roster/#supporting-agents","title":"Supporting Agents","text":"<p>These agents run on the same OpenClaw instance but serve Dobby's personal or other-client contexts.</p> Agent Session Purpose <code>coding-agent</code> <code>agent:coding-agent:main</code> General-purpose coding assistant for Dobby <code>screen-dev</code> <code>agent:screen-dev:main</code> Frontend for Dobby's 5\" touchscreen UI (Flask + Alpine.js + Tailwind, Pi 5) <code>secops</code> <code>agent:secops:main</code> Security auditing for OpenClaw deployments and host hardening <code>business-analyst</code> <code>agent:business-analyst:main</code> Daily strategic business research for JourneyLoop <code>caitlin-assistant</code> <code>agent:caitlin-assistant:main</code> Business assistant for Caitlin Ryan (ocean-themed wellness pivot) <code>voice</code> <code>agent:voice:main</code> Reformats text for voice/TTS output <code>coach-test</code> <code>agent:coach-test:main</code> Staging coaching companion \u2014 Sarah Chen persona"},{"location":"engineering/agent-roster/#collaboration-protocols","title":"Collaboration Protocols","text":""},{"location":"engineering/agent-roster/#issue-lifecycle","title":"Issue Lifecycle","text":"<p>Issues in <code>arc-eng/journeyloop</code> move through these labels, each triggering the responsible agent:</p> <pre><code>graph LR\n    A[needs-spec] --&gt; B[needs-ux]\n    B --&gt; C[needs-tech-spec]\n    C --&gt; D[needs-review]\n    D --&gt; E[ready-for-dev]\n    E --&gt; F[in-progress]\n    F --&gt; G[done]\n\n    style D fill:#f4a261,stroke:#e76f51,color:#000\n    style E fill:#2a9d8f,stroke:#264653,color:#fff</code></pre> <p>Marco's Gate</p> <p>Marco approves transitions at <code>needs-review</code> before work proceeds to <code>ready-for-dev</code>.</p>"},{"location":"engineering/agent-roster/#agent-to-agent-communication","title":"Agent-to-Agent Communication","text":"<p>Agents dispatch work to each other via:</p> <pre><code>sessions_send(sessionKey=\"agent:&lt;name&gt;:main\", message=\"...\")\n</code></pre> <p>Never Use Slack @mentions</p> <p>Bots don't receive Slack @mentions reliably. Always use <code>sessions_send</code> for agent-to-agent dispatch.</p>"},{"location":"engineering/agent-roster/#slack-channels","title":"Slack Channels","text":"Channel Purpose <code>#development</code> Work log \u2014 short updates after every completed task <code>#reviews</code> Escalation to Marco \u2014 always includes specific questions or decisions needed <code>#bot-problems</code> Blockers and errors that need human attention"},{"location":"engineering/agent-roster/#marcos-role","title":"Marco's Role","text":"<p>Marco Lamina is the founder and primary stakeholder.</p> <ul> <li>Approves work before agents start (no autonomous sprinting)</li> <li>Makes product prioritization calls</li> <li>Reviews tech specs and UX before dev proceeds</li> <li>Has final say on architecture trade-offs, vendor decisions, and scope</li> </ul> <p>Escalation Triggers</p> <p>Agents escalate to Marco when:</p> <ul> <li>Architecture decisions carry significant trade-offs</li> <li>Technical blockers require business context</li> <li>Effort estimate exceeds expectations by &gt;2\u00d7</li> </ul>"},{"location":"engineering/agent-roster/#repos","title":"Repos","text":"Repo Purpose <code>arc-eng/journeyloop</code> Main Django codebase \u2014 user stories, feature specs, bugs, tech specs, ADRs <code>arc-eng/journeyloop-startup-assistant</code> Planning \u2014 roadmap, business intel, revenue analysis, strategic decisions <code>arc-eng/journeyloop-docs</code> Documentation site (this site) <code>arc-eng/journeyloop/operator/</code> OpenClaw companion infrastructure scripts (monorepo \u2014 migrated from archived <code>arc-eng/companion-operator</code>) <p>Last updated: 2026-02-23</p>"},{"location":"engineering/agent-task-queue/","title":"Agent Task Queue","text":"<p>The task queue is how JourneyLoop agents assign work to each other and track it across heartbeat cycles. It replaces ad-hoc Slack messages and ephemeral memory as the coordination layer for async agent-to-agent delegation.</p>"},{"location":"engineering/agent-task-queue/#why-it-exists","title":"Why It Exists","text":"<p>Before the task queue, agents had no reliable way to assign work to another agent. A PM could send a Slack message to the SWE agent, but if the SWE session restarted \u2014 or if the message was buried \u2014 the task was lost. Agents also couldn't inspect what work was pending for their teammates.</p> <p>The task queue solves this with three properties:</p> <ul> <li>Persistent \u2014 tasks survive session restarts and gateway reboots</li> <li>Agent-scoped \u2014 each agent has its own queue; no shared mutable state</li> <li>Inspectable \u2014 JSON files in the workspace, readable by any agent or human</li> </ul>"},{"location":"engineering/agent-task-queue/#architecture","title":"Architecture","text":"<p>Each agent's queue lives at:</p> <pre><code>~/.openclaw/workspace/agents/&lt;name&gt;/TASKS.json\n</code></pre> <p>The file is created automatically the first time a task is added to an agent. All agents can read and write all queues \u2014 there's no access control. Trust is the protocol.</p> <p>Tasks have five statuses: <code>pending</code> \u2192 <code>in-progress</code> \u2192 <code>done</code> / <code>failed</code> / <code>dropped</code>.</p> <p>Priority is <code>high</code> &gt; <code>normal</code> &gt; <code>low</code>. Within the same priority tier, the oldest task is picked first (FIFO). This keeps the queue predictable and prevents starvation.</p>"},{"location":"engineering/agent-task-queue/#heartbeat-integration","title":"Heartbeat Integration","text":"<p>On every heartbeat, each agent:</p> <ol> <li>Picks the next pending task: <code>python3 skills/tasks/scripts/tasks.py pick --agent &lt;name&gt;</code></li> <li>If nothing is returned \u2014 stops and replies <code>HEARTBEAT_OK</code></li> <li>Works on the task</li> <li>Marks it done or failed</li> </ol> <p>One task per heartbeat. No exceptions. Agents don't loop through the queue in a single run. This keeps each heartbeat bounded and ensures that long tasks don't block the agent indefinitely.</p> <p>Don't chain tasks in a single heartbeat</p> <p>Picking a second task after finishing the first leads to unbounded run times and makes failure harder to diagnose. The next heartbeat will pick the next task.</p>"},{"location":"engineering/agent-task-queue/#cross-agent-assignment","title":"Cross-Agent Assignment","text":"<p>Any agent can add a task for any other agent:</p> <pre><code>python3 skills/tasks/scripts/tasks.py add \\\n  --agent swe \\\n  --title \"Implement companion memory model\" \\\n  --notes \"See tech-spec: planning/companion/memory-system/tech-spec.md\" \\\n  --priority high \\\n  --added-by cto\n</code></pre> <p>This is the primary coordination mechanism between agents. When the PM finishes a brief, it adds a task to the UX queue. When the CTO finishes a tech spec, it adds a task to the SWE queue. No Slack ping required.</p>"},{"location":"engineering/agent-task-queue/#failure-handling","title":"Failure Handling","text":"<p>Failed tasks are never automatically cleaned up. They stay in the queue with <code>status: \"failed\"</code>, the error message, and a retry count.</p> <p>This is intentional. Failed tasks are diagnostic signals \u2014 they tell the <code>doctor</code> agent (or Dobby) what broke, when, and how many times it's been tried. Cleaning them up automatically would erase that history.</p> <pre><code>stateDiagram-v2\n    [*] --&gt; pending : task added\n    pending --&gt; in_progress : pick\n    in_progress --&gt; done : done\n    in_progress --&gt; failed : fail\n    in_progress --&gt; dropped : drop\n    failed --&gt; in_progress : retry (manual)\n    failed --&gt; dropped : drop (doctor decision)</code></pre> <p>Done and dropped tasks older than 7 days are removed by <code>clean</code>. Failed tasks are exempt.</p>"},{"location":"engineering/agent-task-queue/#ceo-team-digest","title":"CEO Team Digest","text":"<p>The CEO agent runs a team-wide digest on every heartbeat (every 30 minutes, 8am\u201310pm PST). It's the oversight layer built on top of the task queue \u2014 the mechanism that converts agent activity into situational awareness for Marco.</p>"},{"location":"engineering/agent-task-queue/#how-it-works","title":"How It Works","text":"<p>On each heartbeat, the CEO scans all agents' completed and failed tasks since its last check:</p> <pre><code>python3 skills/tasks/scripts/tasks.py digest \\\n  --since \"$(cat agents/ceo/last_digest_ts.txt 2&gt;/dev/null || echo '1970-01-01T00:00:00+00:00')\"\n</code></pre> <p>The timestamp of the last digest is stored in <code>agents/ceo/last_digest_ts.txt</code> and updated after every run. This ensures no task is reported twice.</p> <p>If something happened \u2014 the CEO sends Marco a Slack DM interpreting the work. Not a list of task IDs. A read on what the team accomplished, what it means, and whether anything needs attention. Three to five sentences. If something failed, the CEO names the impact and what should happen next.</p> <p>If nothing happened \u2014 the CEO updates the timestamp file and replies <code>HEARTBEAT_OK</code>. Marco gets no message.</p>"},{"location":"engineering/agent-task-queue/#the-hybrid-model","title":"The Hybrid Model","text":"<p>The design separates two concerns:</p> <ul> <li>Done tasks are batched. Marco gets a digest at most every 30 minutes, not a ping for every completed task. Low-stakes work doesn't interrupt.</li> <li>Failed tasks surface immediately. When the CEO runs its digest and finds failures, they're flagged prominently \u2014 with error details and retry counts \u2014 regardless of how minor the task seemed.</li> </ul> <p>This means failures are never silently lost in a queue. The CEO is the mechanism that turns a <code>status: \"failed\"</code> entry into a human-visible alert.</p>"},{"location":"engineering/agent-task-queue/#ceo-knowledge-base","title":"CEO Knowledge Base","text":"<p>After each digest, the CEO updates <code>agents/ceo/MEMORY.md</code> with key takeaways \u2014 patterns, recurring failures, velocity signals. This gives the CEO a running picture of team health across heartbeats, not just point-in-time snapshots.</p> <pre><code>sequenceDiagram\n    participant CEO\n    participant tasks.py\n    participant Marco\n\n    CEO-&gt;&gt;tasks.py: digest --since &lt;last_ts&gt;\n    tasks.py--&gt;&gt;CEO: done/failed tasks + new timestamp\n    alt Tasks found\n        CEO-&gt;&gt;CEO: update last_digest_ts.txt\n        CEO-&gt;&gt;CEO: update MEMORY.md with takeaways\n        CEO-&gt;&gt;Marco: Slack DM (interpreted summary)\n    else No tasks\n        CEO-&gt;&gt;CEO: update last_digest_ts.txt\n        CEO--&gt;&gt;CEO: HEARTBEAT_OK (silent)\n    end</code></pre>"},{"location":"engineering/agent-task-queue/#cli-quick-reference","title":"CLI Quick Reference","text":"<p>The skill lives at <code>skills/tasks/scripts/tasks.py</code>. Full reference in <code>skills/tasks/SKILL.md</code>.</p> Command Purpose <code>pick --agent NAME</code> Pick next pending task (marks in-progress) <code>done ID --agent NAME --result \"...\"</code> Mark done with summary <code>fail ID --agent NAME --error \"...\"</code> Mark failed \u2014 persists for diagnosis <code>add --agent NAME --title \"...\"</code> Add a task to any agent's queue <code>list [--agent NAME] [--status pending]</code> Inspect queues <code>digest [--since TIMESTAMP]</code> Done/failed summary for CEO digest <code>clean [--days 7]</code> Remove old done/dropped tasks <p>Task IDs support prefix matching \u2014 the first 8 characters are enough.</p>"},{"location":"engineering/label-routing/","title":"GitHub Label \u2192 Agent Routing","text":"<p>Applying a label to a GitHub issue is all it takes to route work to an agent. A poller checks <code>arc-eng/journeyloop</code> every 15 minutes, maps new labels to agent queues, and creates tasks automatically. No Slack message, no manual dispatch.</p>"},{"location":"engineering/label-routing/#why-labels","title":"Why Labels","text":"<p>Labels are already how the team tracks issue state. Routing based on them adds zero friction for Marco \u2014 the same action that advances an issue through the lifecycle also dispatches work to the right agent.</p> <p>The alternative (a separate dispatch step, or sending a Slack message to each agent) introduces a second system to remember and a second place to check. Labels collapse both into one.</p>"},{"location":"engineering/label-routing/#routing-map","title":"Routing Map","text":"Label Routes to Task created <code>needs-spec</code> PM Write product spec (brief.md) for the issue <code>needs-ux</code> UX Design UX concept / wireframes <code>needs-docs</code> Docs Write documentation for the feature <code>auto-build</code> SWE Implement the changes and open a PR <code>needs-code-review</code> CTO Automated code review on the PR <code>needs-human</code> Marco Slack DM \u2014 requires founder attention"},{"location":"engineering/label-routing/#how-it-works","title":"How It Works","text":"<pre><code>sequenceDiagram\n    participant Marco\n    participant GitHub\n    participant Poller as label_tasks poller\n    participant Queue as Agent task queue\n    participant Agent\n\n    Marco-&gt;&gt;GitHub: Apply label to issue\n    Note over Poller: Runs every 15 minutes\n    Poller-&gt;&gt;GitHub: Fetch recently labeled issues\n    Poller-&gt;&gt;Queue: Create task for target agent\n    Agent-&gt;&gt;Queue: pick (next heartbeat)\n    Agent-&gt;&gt;Agent: Work the task\n    Agent-&gt;&gt;Queue: done / fail</code></pre> <ol> <li>Marco applies a label to an issue in <code>arc-eng/journeyloop</code></li> <li>The <code>label_tasks</code> poller fires within 15 minutes</li> <li>A task is created in the target agent's queue with the issue as context</li> <li>The agent picks it up at its next heartbeat and works it</li> <li>The agent marks done or failed \u2014 no manual follow-up needed</li> </ol>"},{"location":"engineering/label-routing/#other-notable-labels","title":"Other Notable Labels","text":"<p>These labels don't trigger agent routing but are part of the shared label vocabulary:</p> Label Meaning <code>ready-for-dev</code> Issue is scoped and ready for development <code>needs-refinement</code> CTO input needed before dev starts <code>needs-work</code> PR was reviewed and requires changes <code>needs-review</code> PR needs code review <code>bug</code> \u00b7 <code>feature</code> \u00b7 <code>refactoring</code> \u00b7 <code>technical-debt</code> Standard categorization"},{"location":"engineering/label-routing/#relationship-to-the-task-queue","title":"Relationship to the Task Queue","text":"<p>Label routing is the entry point into the agent task queue. The poller creates tasks using the same <code>tasks.py add</code> mechanism any agent can use directly. From the agent's perspective, a label-triggered task looks identical to a task added by another agent \u2014 it's just work in the queue.</p> <p>This means label-routed tasks inherit all task queue properties: priority ordering, failure tracking, CEO digest visibility, and one-task-per-heartbeat discipline.</p>"},{"location":"engineering/local-dev/","title":"Local Development","text":"<p>Tooling and conventions for running JourneyLoop on Dobby for local development and UX review.</p>"},{"location":"engineering/local-dev/#ux-mockup-server","title":"UX Mockup Server","text":"<p>Mockups live in the JourneyLoop Django app and are served via the local dev server.</p> <p>Start the server:</p> <pre><code>cd /home/dobby/Projects/journeyloop-ux &amp;&amp; DEBUG=True poetry run python manage.py runserver 8765\n</code></pre> <p><code>DEBUG=True</code> is required</p> <p>Static files (Tailwind CSS) are not served by Django in production mode. Without <code>DEBUG=True</code>, mockup pages will render without styles.</p> <p>The server binds to <code>127.0.0.1:8765</code>. Mockup routes follow the pattern:</p> <pre><code>http://127.0.0.1:8765/mockups/&lt;slug&gt;/\n</code></pre>"},{"location":"engineering/local-dev/#taking-mockup-screenshots","title":"Taking Mockup Screenshots","text":"<p>The browser tool cannot screenshot <code>localhost</code> URLs. Use Playwright headless instead.</p> <p>Prerequisites (one-time install):</p> <pre><code>pip3 install playwright --break-system-packages\npython3 -m playwright install chromium\n</code></pre> <p>Screenshot a mockup:</p> <pre><code>python3 -c \"\nfrom playwright.sync_api import sync_playwright\nwith sync_playwright() as p:\n    browser = p.chromium.launch(headless=True, args=['--no-sandbox'])\n    page = browser.new_page(viewport={'width': 1400, 'height': 900})\n    page.goto('http://127.0.0.1:8765/mockups/&lt;slug&gt;/', wait_until='networkidle', timeout=15000)\n    page.screenshot(path='/home/dobby/.openclaw/media/screenshots/&lt;slug&gt;.png', full_page=True)\n    browser.close()\n\"\n</code></pre> <p>Replace <code>&lt;slug&gt;</code> with the mockup route name in both the URL and the output path.</p> <p>Analyze the screenshot:</p> <pre><code>image(images=['/home/dobby/.openclaw/media/screenshots/&lt;slug&gt;.png'], prompt=\"...\")\n</code></pre>"},{"location":"engineering/local-dev/#gotchas","title":"Gotchas","text":"<p>Use <code>127.0.0.1</code>, not <code>localhost</code></p> <p>On this machine, <code>localhost</code> may resolve to <code>::1</code> (IPv6). The Django dev server binds to IPv4 only (<code>127.0.0.1:8765</code>), so IPv6 resolution will fail to connect. Always use the explicit IPv4 address.</p> <p>Chromium headless shell, not full Chromium</p> <p><code>python3 -m playwright install chromium</code> installs the headless shell variant \u2014 lighter than full Chromium and sufficient for screenshots.</p>"},{"location":"engineering/local-dev/#verified-setup-issue-138","title":"Verified Setup (issue #138)","text":"<p>This workflow was confirmed working on Dobby as of 2026-02-24.</p> Component Version / Detail Dev server Django via Poetry, port 8765 Screenshot tool Playwright + Chromium headless (<code>--no-sandbox</code>) Viewport 1400\u00d7900 Output path <code>/home/dobby/.openclaw/media/screenshots/</code> <p>Last updated: 2026-02-24</p>"},{"location":"engineering/operator-runbook/","title":"Companion Operator Infrastructure","text":"<p>How the GCP companion operator is managed and how its agents coordinate. This covers the operational layer on the VM \u2014 not the companion agents themselves, but the infrastructure that runs and maintains them.</p> <p>For provisioning and architecture, see the Operator Guide.</p>"},{"location":"engineering/operator-runbook/#heartbeat-broadcasting","title":"Heartbeat Broadcasting","text":"<p>The operator can trigger heartbeats for all companion agents at once using <code>heartbeat-all.sh</code>:</p> <pre><code>cd ~/journeyloop/operator\n./scripts/heartbeat-all.sh\n</code></pre> <p>This also uses an <code>--agent ALL</code> flag on <code>tasks.py</code>, which applies a command across every agent's queue simultaneously. It's used when the operator needs to push a coordinated update \u2014 for example, triggering all agents to pick up a configuration change or run a specific task.</p> <p>Individual agent heartbeats are still managed by their own cron schedules. The broadcast mechanism is for operator-initiated coordination, not routine operation.</p>"},{"location":"engineering/operator-runbook/#operator-controlled-heartbeat-cron","title":"Operator-Controlled Heartbeat Cron","text":"<p>The operator maintains a cron schedule for heartbeats with logging. This means:</p> <ul> <li>The operator (not individual agents) owns the heartbeat schedule</li> <li>Heartbeat runs are logged centrally on the VM, not just inside each agent session</li> <li>The operator can temporarily suppress or modify heartbeats for maintenance without touching each agent's config</li> </ul>"},{"location":"engineering/operator-runbook/#promotion-pipeline","title":"Promotion Pipeline","text":"<p>The <code>promote.sh</code> script handles promoting a new companion configuration to all live agents. As of Feb 2026, promotion auto-migrates all live agents \u2014 every companion agent picks up the new configuration as part of the promote run.</p> <p>Previously, migration was a separate step. The consolidation removes the risk of partially-migrated fleets: every promote is atomic across all agents.</p> Promote to all live agents<pre><code>cd ~/journeyloop/operator\n./scripts/promote.sh\n</code></pre> <p>Promotion is irreversible during the run</p> <p>There's no partial rollback once promote starts migrating agents. Test in staging first.</p>"},{"location":"engineering/operator-runbook/#skill-distribution-central-skills-directory","title":"Skill Distribution: Central Skills Directory","text":"<p>Companion agents share a central <code>skills/</code> directory on the operator VM rather than maintaining per-agent skill copies.</p> <p>Before: Each agent workspace had its own copy of shared skills. Updating a skill meant merging changes into every agent.</p> <p>After: A single <code>skills/</code> directory at the operator level is referenced by all agents. Agent workspaces contain only agent-specific files (<code>SOUL.md</code>, <code>MEMORY.md</code>, credentials, etc.).</p> <p>This makes skill updates atomic \u2014 change once, all agents see it on next heartbeat. It also keeps agent workspaces lean: each workspace is only what's unique to that coach's agent.</p> <p>The <code>operator/agent</code> files (templates, workspace structure) are kept separate from the shared <code>skills/</code> directory. Operator-level config doesn't bleed into agent workspaces.</p>"},{"location":"engineering/operator-runbook/#task-queue-for-the-operator-agent","title":"Task Queue for the Operator Agent","text":"<p>The main operator agent now has access to the task queue skill for cross-agent dispatch. The operator can add tasks to individual companion agent queues:</p> <pre><code>python3 skills/tasks/scripts/tasks.py add \\\n  --agent &lt;coach-agent-id&gt; \\\n  --title \"Reload client profile for next session\" \\\n  --added-by operator\n</code></pre> <p>This closes the coordination loop: the operator can not only broadcast heartbeats but also assign specific work to specific agents without sending a chat message.</p> <p>Combined with <code>--agent ALL</code>, the operator can add the same task to every agent's queue at once.</p>"},{"location":"engineering/process/","title":"Engineering Process","text":"<p>How the JourneyLoop agent team manages issues, specs, and development workflow.</p>"},{"location":"engineering/process/#repos","title":"Repos","text":"Repo Purpose Short Ref <code>arc-eng/journeyloop</code> Django app (code) JL <code>arc-eng/journeyloop-startup-assistant</code> Planning, roadmap, specs JL-SA <code>arc-eng/journeyloop-docs</code> Documentation site JL-Docs"},{"location":"engineering/process/#planning-docs-one-folder-per-feature","title":"Planning Docs: One Folder Per Feature","text":"<p>Every feature gets a folder under its project namespace:</p> <pre><code>planning/&lt;project&gt;/&lt;feature&gt;/\n  brief.md          \u2190 Product spec: user stories, acceptance criteria\n  ux.md             \u2190 UX concept: layout, interaction, wireframes\n  tech-spec.md      \u2190 Technical architecture: system design, decisions\n</code></pre> <p>Not every feature needs every file</p> <p>Backend-only features skip <code>ux.md</code>. Simple features might only need <code>brief.md</code>.</p> <p>Example structure:</p> <pre><code>planning/companion/\n  memory-system/\n    brief.md\n    tech-spec.md\n  interface/\n    brief.md\n    ux.md\n    tech-spec.md\n  skill-system/\n    brief.md\n    ux.md\n    tech-spec.md\n</code></pre>"},{"location":"engineering/process/#issues-one-per-feature","title":"Issues: One Per Feature","text":"<p>Each feature has one tracking issue in <code>arc-eng/journeyloop-startup-assistant</code>. The substance lives in the planning folder \u2014 the issue is lightweight.</p>"},{"location":"engineering/process/#issue-format","title":"Issue Format","text":"<pre><code>## [emoji] Feature Name\n\n**Planning:** `planning/&lt;project&gt;/&lt;feature&gt;/`\n\n| Vertical     | Status         |\n|-------------|----------------|\n| Product Spec | \u2705 Done / \ud83d\udd32 Not started / \u2796 N/A |\n| UX Concept   | \u2705 Done / \ud83d\udd32 Not started / \u2796 N/A |\n| Tech Spec    | \u2705 Done / \ud83d\udd32 Not started / \u2796 N/A |\n\n### Summary\nOne paragraph describing the feature and why it matters.\n</code></pre> <p>The status table is updated as verticals are completed.</p>"},{"location":"engineering/process/#lifecycle-feature-state-machine","title":"Lifecycle: Feature State Machine","text":"<p>Each feature issue carries exactly one lifecycle label at a time. The label answers: \"What does this feature need next?\"</p> <pre><code>stateDiagram-v2\n    [*] --&gt; needs_spec : Feature created\n    needs_spec --&gt; needs_ux : PM writes brief\n    needs_ux --&gt; needs_tech_spec : UX concept done\n    needs_tech_spec --&gt; needs_review : CTO writes tech spec\n    needs_review --&gt; ready_for_dev : Marco approves\n    ready_for_dev --&gt; [*] : SWE ships it\n\n    needs_spec : needs-spec\n    needs_ux : needs-ux\n    needs_tech_spec : needs-tech-spec\n    needs_review : needs-review\n    ready_for_dev : ready-for-dev</code></pre>"},{"location":"engineering/process/#lifecycle-labels","title":"Lifecycle Labels","text":"Label Set By Means <code>needs-spec</code> \u2014 Feature needs a product spec (brief.md) <code>needs-ux</code> PM Brief done, needs UX concept <code>needs-tech-spec</code> PM/UX Ready for CTO to write tech-spec.md <code>needs-review</code> CTO All specs done, needs Marco's review <code>ready-for-dev</code> Marco Fully specced and approved, SWE can implement <code>needs-po-input</code> CTO CTO needs product clarification <code>needs-cto-input</code> PM PM needs technical assessment <code>blocked-technical</code> CTO Technical blocker identified"},{"location":"engineering/process/#escalation-labels-to-marco","title":"Escalation Labels (to Marco)","text":"<p>Escalation labels trigger a ping to Marco</p> Label Action Means <code>needs-founder-decision</code>  Ping Marco Above agent authority \u2014 options + recommendation <code>needs-founder-approval</code>  Ping Marco Both agents signed off, need go/no-go <code>founder-fyi</code> Silent Awareness only"},{"location":"engineering/process/#agent-roles","title":"Agent Roles","text":"Role Owns Transitions PM <code>brief.md</code>, acceptance criteria, prioritization <code>needs-spec</code> \u2192 <code>needs-ux</code> or <code>needs-tech-spec</code> CTO <code>tech-spec.md</code>, architecture decisions, PR review <code>needs-tech-spec</code> \u2192 <code>needs-review</code> UX Agent <code>ux.md</code>, interaction design, wireframes <code>needs-ux</code> \u2192 <code>needs-tech-spec</code> or <code>needs-review</code> Marco Founder decisions, approvals <code>needs-review</code> \u2192 <code>ready-for-dev</code> SWE Implementation, PRs <code>ready-for-dev</code> \u2192 done"},{"location":"engineering/process/#label-taxonomy","title":"Label Taxonomy","text":"Type Area Size Priority Category <p><code>feature</code> \u00b7 <code>bug</code> \u00b7 <code>tech-debt</code> \u00b7 <code>enhancement</code> \u00b7 <code>adr</code></p> <p><code>backend</code> \u00b7 <code>frontend</code> \u00b7 <code>api</code> \u00b7 <code>cli</code> \u00b7 <code>calendar</code> \u00b7 <code>ai</code></p> <p><code>size/S</code> \u00b7 <code>size/M</code> \u00b7 <code>size/L</code> \u00b7 <code>size/XL</code></p> <p><code>p0-critical</code> \u00b7 <code>p1-high</code> \u00b7 <code>p2-medium</code> \u00b7 <code>p3-low</code></p> <p><code>vision</code> \u00b7 <code>bug</code> \u00b7 <code>enhancement</code> \u00b7 <code>epic</code></p>"},{"location":"engineering/process/#documentation-rules","title":"Documentation Rules","text":"<p>Every label change gets a comment</p> <p>Explain WHY the label changed and WHO needs to act next.</p>"},{"location":"engineering/process/#comment-signing","title":"Comment signing","text":"<p>All agents sign their comments:</p> <ul> <li><code>\u2014 PO Agent</code></li> <li><code>\u2014 CTO Agent</code></li> <li><code>\u2014 UX Agent</code></li> <li><code>\u2014 SWE Agent</code></li> </ul>"},{"location":"engineering/process/#specs-are-files-not-comments","title":"Specs are files, not comments","text":"<p>Never paste spec content into issue comments</p> <p>Tech specs, UX concepts, and briefs are files in the planning folder. Issue comments are transition signals only \u2014 one line linking the file. Pasting specs into comments creates drift if the file changes.</p>  Good comment Bad comment <pre><code>Tech spec written: `planning/companion/interface/tech-spec.md`\nRemoving `needs-tech-spec`, adding `needs-review`.\n\u2014 CTO Agent\n</code></pre> <pre><code>## Tech Spec\n### Architecture\nWe will use Django REST framework to...\n[2000 words of spec content pasted inline]\n\u2014 CTO Agent\n</code></pre>"},{"location":"engineering/process/#acceptance-criteria-use-checkboxes","title":"Acceptance criteria use checkboxes","text":"<pre><code>## Acceptance Criteria\n- [ ] CompanionMemory model created with required fields\n- [ ] Migration generated and tested\n- [ ] Unit tests for model validation\n</code></pre> <p>When checking off criteria, comment what you did:</p> <pre><code>\u2705 Checked off \"Add companion memory model\"\n\u2014 Added CompanionMemory in companion/models.py with migration 0001.\n\u2014 SWE Agent\n</code></pre>"},{"location":"engineering/process/#epics","title":"Epics","text":"<p>Epics group related features. They're checklist issues \u2014 no specs or acceptance criteria of their own.</p> <pre><code>## [emoji] Epic Name\nWhy this matters \u2014 1-2 sentences.\n\n### Features\n- [ ] #XX \u2014 Feature Name (`current-label`)\n- [ ] #YY \u2014 Feature Name (`current-label`)\n- [x] #ZZ \u2014 Feature Name (`done`)\n</code></pre> <p>Max 2 active epics at any time.</p>"},{"location":"engineering/process/#implementation-issues","title":"Implementation Issues","text":"<p>When a feature reaches <code>ready-for-dev</code>, implementation issues are created in <code>arc-eng/journeyloop</code> (the code repo):</p> <pre><code>**As a** [role],\n**I want** [goal]\n**so that** [value].\n\n## Acceptance Criteria\n- [ ] Testable condition (max 3 per issue \u2014 split if more)\n\n## Planning\nSee: `planning/&lt;project&gt;/&lt;feature&gt;/` in journeyloop-startup-assistant\n</code></pre>"},{"location":"engineering/process/#slack-channels","title":"Slack Channels","text":"Channel Purpose <code>#development</code> Short log entries for every completed task <code>#reviews</code> Review threads for specs and PRs <code>#scrum</code> Daily standups and sprint coordination"},{"location":"engineering/slack-agent-communication/","title":"Slack Agent Communication Architecture","text":"<p>How JourneyLoop AI agents communicate over Slack: the thread-per-session model, OpenClaw gateway configuration, expected agent behavior, session key mapping, known limitations, and troubleshooting.</p> <p>Internal reference</p> <p>This doc is for the engineering team. It describes the configuration active on all five agent Slack accounts (PM, CTO, UX, SWE, Ray) as of 2026-02-23.</p>"},{"location":"engineering/slack-agent-communication/#1-overview","title":"1. Overview","text":""},{"location":"engineering/slack-agent-communication/#thread-per-session-model","title":"Thread-Per-Session Model","text":"<p>Every Slack channel thread is an isolated agent session. When you post to a channel and the agent replies, OpenClaw creates a thread automatically and binds a new session to it. Subsequent messages in that thread are part of the same session \u2014 the agent has context continuity for that entire conversation.</p> <pre><code>1. User posts \"@SWE implement #126\" in #development\n2. OpenClaw routes to SWE \u2192 new channel session\n3. SWE replies \u2192 Slack auto-creates a thread (replyToMode: \"first\")\n4. Thread TS captured \u2192 new session key: agent:swe:slack:channel:&lt;id&gt;:thread:&lt;ts&gt;\n5. User replies in thread with @SWE \u2192 routes to existing thread session\n6. SWE continues with full thread context\n</code></pre>"},{"location":"engineering/slack-agent-communication/#why-thread-per-session","title":"Why Thread-Per-Session?","text":"Concern Before (flat channel) After (thread-per-session) Context isolation All channel messages bleed into one session Each thread = its own conversation Parallel conversations Agents confused by interleaved topics Clean isolation per thread History retrieval Full channel history loaded (noisy) Thread history only (<code>historyScope: \"thread\"</code>) Auditability Hard to trace a request end-to-end Thread = single logical unit <p>DMs and group DMs are intentionally not threaded \u2014 they stay as flat conversations (see Gateway Configuration below).</p>"},{"location":"engineering/slack-agent-communication/#2-gateway-configuration","title":"2. Gateway Configuration","text":"<p>These settings are applied to all five Slack accounts in each agent's <code>openclaw.json</code>.</p>"},{"location":"engineering/slack-agent-communication/#replytomode","title":"<code>replyToMode</code>","text":"<pre><code>\"replyToMode\": \"first\"\n</code></pre> <p>The bot's first reply to a channel message creates a Slack thread. This is what triggers thread creation \u2014 the bot does not post in the channel root for subsequent replies.</p>"},{"location":"engineering/slack-agent-communication/#replytomodebychattype","title":"<code>replyToModeByChatType</code>","text":"<pre><code>\"replyToModeByChatType\": {\n  \"channel\": \"first\",\n  \"direct\": \"off\",\n  \"group\": \"off\"\n}\n</code></pre> <ul> <li><code>channel: \"first\"</code> \u2014 thread on first reply (channel posts only)</li> <li><code>direct: \"off\"</code> \u2014 DMs remain flat; no thread wrapping</li> <li><code>group: \"off\"</code> \u2014 group DMs remain flat</li> </ul>"},{"location":"engineering/slack-agent-communication/#thread-history","title":"Thread History","text":"<pre><code>\"thread\": {\n  \"historyScope\": \"thread\",\n  \"inheritParent\": false,\n  \"initialHistoryLimit\": 20\n}\n</code></pre> <code>historyScope: \"thread\"</code> Agent only sees messages within the thread. Parent channel messages are excluded. <code>inheritParent: false</code> Thread sessions do not inherit context from the parent channel session. Each thread starts fresh. <code>initialHistoryLimit: 20</code> On first load of an existing thread, up to 20 prior messages are loaded for context."},{"location":"engineering/slack-agent-communication/#session-reset","title":"Session Reset","text":"<pre><code>\"session\": {\n  \"resetByType\": {\n    \"thread\": {\n      \"mode\": \"idle\",\n      \"idleMinutes\": 1440\n    }\n  }\n}\n</code></pre> <p>Thread sessions reset after 24 hours of inactivity (<code>1440</code> minutes). After reset, the next message in the thread starts a fresh session \u2014 prior thread history is re-loaded up to <code>initialHistoryLimit</code>.</p>"},{"location":"engineering/slack-agent-communication/#3-agent-instructions","title":"3. Agent Instructions","text":"<p>These rules apply to all JourneyLoop agents (PM, CTO, UX, SWE, Ray). They are codified in each agent's <code>AGENTS.md</code> and the shared <code>ORG.md</code> and <code>MEMORY.md</code>.</p>"},{"location":"engineering/slack-agent-communication/#reply-behavior-by-context","title":"Reply Behavior by Context","text":"Channel ThreadDirect MessageProactive / Agent-Initiated Post <ul> <li>Reply naturally \u2014 OpenClaw routes the reply back to the same thread automatically</li> <li>Do not use the <code>message</code> tool for thread replies; that would create a separate DM or mis-routed post</li> <li>Stay within the thread; never surface a thread response back to the channel root</li> </ul> <ul> <li>Use the <code>message</code> tool explicitly to reply</li> <li>DMs have no thread; responses go directly to the DM conversation</li> <li>Session key is DM-scoped (see Session Keys)</li> </ul> <ul> <li>Always use the <code>message</code> tool with a fully-qualified <code>target</code> (channel ID or user ID)</li> <li>Do not assume a channel context exists</li> <li>If starting a new channel topic, post to the channel root \u2014 do not reply to an existing thread unless explicitly continuing one</li> </ul>"},{"location":"engineering/slack-agent-communication/#the-acknowledge-first-rule","title":"The Acknowledge-First Rule","text":"<p>Always acknowledge before starting long tasks</p> <p>If a request will take more than a few seconds, send a short acknowledgment first, then execute.</p> <pre><code>\u2705 \"On it \u2014 reviewing the spec now.\"\n\u2705 \"Got it, running the build.\"\n\u274c (silence for 30 seconds, then a wall of output)\n</code></pre> <p>This prevents users from thinking the bot missed the message, and makes thread conversations feel responsive.</p>"},{"location":"engineering/slack-agent-communication/#4-session-keys","title":"4. Session Keys","text":"<p>Session keys are how OpenClaw tracks conversation state. Each distinct context gets its own key.</p> Context Session Key Format Channel (root) <code>agent:&lt;id&gt;:slack:channel:&lt;channelId&gt;</code> Channel Thread <code>agent:&lt;id&gt;:slack:channel:&lt;channelId&gt;:thread:&lt;threadTs&gt;</code> Direct Message <code>agent:&lt;id&gt;:slack:dm:&lt;userId&gt;</code> <p>Key points:</p> <ul> <li><code>&lt;id&gt;</code> is the agent identifier (e.g. <code>pm</code>, <code>cto</code>, <code>ux</code>, <code>swe</code>, <code>ray</code>)</li> <li><code>&lt;channelId&gt;</code> is the Slack channel ID (e.g. <code>C08ABCDEF</code>)</li> <li><code>&lt;threadTs&gt;</code> is the Slack thread timestamp of the parent message (e.g. <code>1740349800.123456</code>)</li> <li><code>&lt;userId&gt;</code> is the Slack user ID for DMs (e.g. <code>U01ABCDEF</code>)</li> </ul> <p>A channel root message and a thread off that same message are different sessions. This is intentional \u2014 threads are isolated.</p>"},{"location":"engineering/slack-agent-communication/#5-known-limitations","title":"5. Known Limitations","text":""},{"location":"engineering/slack-agent-communication/#implicit-mention-bug-openclawopenclaw24816","title":"Implicit Mention Bug \u2014 <code>openclaw/openclaw#24816</code>","text":"<p>Issue: Thread follow-up messages that do not <code>@mention</code> the bot are silently ignored. The agent never sees them.</p> <p>Root cause: OpenClaw's implicit mention check compares <code>parent_user_id === botUserId</code> \u2014 i.e., it only triggers on threads where the bot started the thread. Since the thread is created by the user's channel post (and the bot replies into it), <code>parent_user_id</code> is the user, not the bot. The implicit mention never fires.</p> <p>Status: Filed at openclaw/openclaw#24816. No fix timeline yet.</p> <p>Workaround:</p> <p>Always @mention the bot in thread replies</p> <p>Every message in a thread directed at the agent must explicitly <code>@mention</code> the bot account.</p> <pre><code>\u274c \"Can you check the spec again?\"          \u2190 bot never sees this\n\u2705 \"@pm-agent Can you check the spec again?\" \u2190 works correctly\n</code></pre> <p>This applies to all thread follow-ups, not just the first one. Document this in any user-facing onboarding for Slack.</p>"},{"location":"engineering/slack-agent-communication/#6-troubleshooting","title":"6. Troubleshooting","text":""},{"location":"engineering/slack-agent-communication/#agent-not-responding-in-a-thread","title":"Agent not responding in a thread","text":"<p>Symptoms: You reply in a thread, no response.</p> Check What to do Did you <code>@mention</code> the bot? Required due to bug #24816 (see Known Limitations above). Add the <code>@mention</code> and retry. Is the session idle-expired? Sessions reset after 24h idle. The next <code>@mention</code> in the thread will restart the session with the last 20 messages as context. Is the agent account active? Check <code>openclaw gateway status</code> on Dobby. All five agent Slack accounts run through the same gateway. Is the channel configured? Confirm the channel is in the agent's allowed channels list in <code>openclaw.json</code>."},{"location":"engineering/slack-agent-communication/#response-goes-to-dm-instead-of-the-thread","title":"Response goes to DM instead of the thread","text":"<p>Symptoms: Agent responds in a DM to you rather than in the channel thread.</p> <p>Cause: The agent used the <code>message</code> tool instead of a natural reply, and the tool resolved to your DM.</p> <p>Fix: Update the agent's <code>AGENTS.md</code> \u2014 reinforce that thread replies must be natural replies, not <code>message</code> tool calls. If an individual agent instance did this, it may have hallucinated a tool call; a session reset usually clears it.</p>"},{"location":"engineering/slack-agent-communication/#response-goes-to-channel-root-instead-of-the-thread","title":"Response goes to channel root instead of the thread","text":"<p>Symptoms: Agent's reply appears in the channel as a top-level post, not in the thread.</p> <p>Cause: Usually a <code>message</code> tool call targeting the channel ID without a <code>threadTs</code>. Or the agent replied before OpenClaw bound the thread session.</p> <p>Fix: Same as above \u2014 reinforce natural reply behavior in <code>AGENTS.md</code>. Check whether <code>replyToMode</code> is set to <code>\"first\"</code> in <code>openclaw.json</code>; if it's <code>\"off\"</code> or missing, threading is disabled.</p>"},{"location":"engineering/slack-agent-communication/#agent-has-no-context-of-earlier-thread-messages","title":"Agent has no context of earlier thread messages","text":"<p>Symptoms: Agent responds as if the thread is brand new, ignoring prior context.</p> <p>Cause 1: Session idle-expired (24h) \u2014 the session was reset. Prior history is re-loaded up to <code>initialHistoryLimit: 20</code>.</p> <p>Cause 2: <code>inheritParent: false</code> is correct behavior \u2014 threads intentionally don't inherit parent channel context.</p> <p>Cause 3: <code>historyScope</code> misconfigured. Verify <code>\"historyScope\": \"thread\"</code> in the agent's gateway config.</p>"},{"location":"engineering/slack-agent-communication/#two-agents-responding-to-the-same-thread","title":"Two agents responding to the same thread","text":"<p>Symptoms: Both e.g. PM and CTO agents reply to the same thread message.</p> <p>Cause: The message <code>@mentioned</code> both bots, or a channel is subscribed by multiple agents.</p> <p>Fix: Be explicit about which agent you're addressing. Each agent monitors specific channels \u2014 review channel assignments in each agent's <code>openclaw.json</code>.</p> <p> Last updated: 2026-02-23 \u2014 configuration applied in the Slack thread sessions restructure.</p>"},{"location":"engineering/troubleshooting/","title":"Troubleshooting","text":"<p>Structure: symptom \u2192 diagnosis \u2192 fix. Every section has real commands. No fluff.</p>"},{"location":"engineering/troubleshooting/#1-quick-health-check","title":"1. Quick Health Check","text":"<p>Run this first. Always.</p> <pre><code># Is the gateway running?\nopenclaw gateway status\n\n# Recent errors?\nopenclaw logs | tail -50\n\n# Active sessions\nopenclaw sessions list\n\n# Cron state\nopenclaw cron list\n\n# Pi resources\nfree -h &amp;&amp; df -h &amp;&amp; uptime\n</code></pre> Check Healthy Unhealthy Gateway status <code>running</code> <code>stopped</code> / no output Log tail No <code>ERROR</code> / <code>FATAL</code> lines Stack traces, repeated crashes Sessions Expected agents listed Missing agents, stuck <code>active</code> sessions Cron <code>enabled: true</code>, recent <code>lastRun</code> <code>enabled: false</code>, <code>lastError</code> set Memory (<code>free -h</code>) &gt;200MB free &lt;100MB free \u2014 OOM risk Disk (<code>df -h</code>) &lt;80% on <code>/</code> &gt;90% \u2014 clean up logs/transcripts <p>Keep a terminal alias</p> <p>Add to <code>~/.bashrc</code>: <code>alias ochealth='openclaw gateway status &amp;&amp; openclaw logs | tail -20 &amp;&amp; free -h &amp;&amp; df -h'</code></p>"},{"location":"engineering/troubleshooting/#2-gateway-issues","title":"2. Gateway Issues","text":""},{"location":"engineering/troubleshooting/#gateway-wont-start","title":"Gateway won't start","text":"<p>Symptoms: <code>openclaw gateway start</code> returns immediately, status stays <code>stopped</code>.</p> <p>Diagnose:</p> <pre><code># Run in foreground to see the actual error\nopenclaw gateway start --foreground\n\n# Check for JSON syntax errors in config\npython3 -c \"import json; json.load(open('$HOME/.openclaw/openclaw.json'))\" &amp;&amp; echo \"JSON OK\"\n\n# Check if port is already in use (default: 5050)\nlsof -i :5050\n# or\nss -tlnp | grep 5050\n</code></pre> <p>Common causes &amp; fixes:</p> Cause Fix Bad JSON in <code>openclaw.json</code> Fix the syntax error reported by <code>python3</code> above Port conflict Kill the conflicting process: <code>kill $(lsof -t -i :5050)</code> Missing env var Check for required vars in config; set via <code>export</code> or <code>.env</code> file Corrupt gateway store <code>rm -rf ~/.openclaw/store &amp;&amp; openclaw gateway start</code> (loses cron state \u2014 re-register crons) <pre><code># Kill whatever is on port 5050 and restart\nkill $(lsof -t -i :5050) &amp;&amp; openclaw gateway start\n</code></pre>"},{"location":"engineering/troubleshooting/#gateway-crashes-keeps-restarting","title":"Gateway crashes / keeps restarting","text":"<p>Symptoms: Gateway starts but dies within minutes; repeated restarts in logs.</p> <p>Diagnose:</p> <pre><code># Check for OOM kills\ndmesg | grep -i oom | tail -10\n\n# Check gateway logs for last error before crash\nopenclaw logs | grep -E \"FATAL|CRASH|killed\" | tail -20\n\n# Check memory at time of crash\ndmesg | grep -E \"oom|memory\" | tail -20\n</code></pre> <p>Fixes:</p> OOM (most common on Pi)Crash loop <pre><code># Confirm OOM kill\ndmesg | grep -i oom | tail -5\n\n# Free memory: stop heavy background processes\n# Then restart gateway with fewer concurrent agents if needed\nopenclaw gateway restart\n</code></pre> <pre><code># Stop, wait, start clean\nopenclaw gateway stop\nsleep 3\nopenclaw gateway start\n\n# If still crashing, check config validity first\npython3 -c \"import json; json.load(open('$HOME/.openclaw/openclaw.json'))\" &amp;&amp; echo \"OK\"\n</code></pre>"},{"location":"engineering/troubleshooting/#config-changes-not-taking-effect","title":"Config changes not taking effect","text":"<p>What hot-reloads vs. what requires restart</p> Setting Hot reload Restart required Agent prompts / instructions \u2705 Yes \u2014 Cron job schedule \u2705 Yes \u2014 New agent registration \u274c No <code>openclaw gateway restart</code> Port / listener config \u274c No <code>openclaw gateway restart</code> Channel credentials (tokens) \u274c No <code>openclaw gateway restart</code> <pre><code># For anything that needs a restart:\nopenclaw gateway restart\n\n# Verify new config loaded (check startup logs)\nopenclaw logs | grep \"config\" | tail -10\n</code></pre>"},{"location":"engineering/troubleshooting/#3-agent-not-responding","title":"3. Agent Not Responding","text":""},{"location":"engineering/troubleshooting/#agent-silent-on-slack","title":"Agent silent on Slack","text":"<p>Diagnose:</p> <pre><code># Is it skipping due to mention requirement?\nopenclaw logs | grep \"no-mention\" | tail -20\n\n# Is the agent registered?\nopenclaw agents list | grep &lt;agent-name&gt;\n\n# Is there an active session stuck open?\nopenclaw sessions list | grep &lt;agent-id&gt;\n</code></pre> <p>Fix by cause:</p> Symptom Cause Fix Logs show <code>no-mention</code> <code>requireMention: true</code>, message didn't @ the bot @ the bot, or set <code>requireMention: false</code> No log entries at all Agent not registered / gateway not running Re-register agent, restart gateway Session shows <code>active</code> but no reply Stuck session Kill it: <code>openclaw sessions kill &lt;session-id&gt;</code>"},{"location":"engineering/troubleshooting/#agent-silent-on-telegram","title":"Agent silent on Telegram","text":"<p>Diagnose:</p> <pre><code># Check webhook status via Telegram Bot API\ncurl -s \"https://api.telegram.org/bot&lt;TOKEN&gt;/getWebhookInfo\" | python3 -m json.tool\n\n# Check logs for Telegram errors\nopenclaw logs | grep -i \"telegram\\|webhook\" | tail -20\n</code></pre> <p>Fixes:</p> <pre><code># Re-set the webhook (replace TOKEN and URL)\ncurl -X POST \"https://api.telegram.org/bot&lt;TOKEN&gt;/setWebhook\" \\\n  -d \"url=https://&lt;your-gateway-url&gt;/telegram/&lt;TOKEN&gt;\"\n\n# Verify it took\ncurl -s \"https://api.telegram.org/bot&lt;TOKEN&gt;/getWebhookInfo\" | python3 -m json.tool\n</code></pre>"},{"location":"engineering/troubleshooting/#agent-session-stuck-never-clears","title":"Agent session stuck (never clears)","text":"<p>Symptoms: <code>openclaw sessions list</code> shows sessions in <code>active</code> state that have been running for hours.</p> <p>Diagnose:</p> <pre><code># Find stuck sessions\nopenclaw sessions list\n\n# Check logs for sessions that never got a completion event\nopenclaw logs | grep \"totalActive\" | tail -30\n</code></pre> <p>Fix:</p> <pre><code># Kill a specific stuck session\nopenclaw sessions kill &lt;session-id&gt;\n\n# Nuclear: kill all active sessions for an agent\nopenclaw sessions list | grep &lt;agent-id&gt;\n# then kill each one\n</code></pre>"},{"location":"engineering/troubleshooting/#agent-lost-identity-amnesia","title":"Agent lost identity / amnesia","text":"<p>Symptoms: Agent doesn't know its name, role, or backstory; behaves like a generic assistant.</p> <p>Diagnose:</p> <pre><code># Run the health check script\npython3 scripts/agent_health_check.py\n\n# Manual checks\nopenclaw agents list | grep &lt;agent-id&gt;   # is workspace/agentDir set?\nls ~/.openclaw/agents/&lt;agent-id&gt;/        # does SOUL.md exist?\ncat ~/.openclaw/agents/&lt;agent-id&gt;/SOUL.md\n</code></pre> <p>Warning</p> <p>If <code>agentDir</code> is missing from the agent registration, every session reset means the agent loses its identity files entirely. Fix the registration config, not just the files.</p> <p>Fix:</p> <pre><code># 1. Verify registration has agentDir\nopenclaw agents show &lt;agent-id&gt;\n\n# 2. If missing, edit openclaw.json to add workspace + agentDir, then restart\nopenclaw gateway restart\n\n# 3. Confirm SOUL.md is in place\nls ~/.openclaw/agents/&lt;agent-id&gt;/SOUL.md\n</code></pre>"},{"location":"engineering/troubleshooting/#4-slack-specific-issues","title":"4. Slack-Specific Issues","text":"<p>See also: Slack Agent Communication for full architecture.</p>"},{"location":"engineering/troubleshooting/#all-bots-respond-to-every-message","title":"All bots respond to every message","text":"<p>Cause: <code>requireMention: false</code> on multiple agents in the same workspace.</p> <p>Diagnose:</p> <pre><code>openclaw agents list  # check requireMention for each Slack agent\n</code></pre> <p>Fix:</p> <p>Set <code>requireMention: true</code> on all agents that shouldn't respond to every message. Only the \"default responder\" agent (if any) should have it false.</p> <pre><code>// openclaw.json \u2014 per-agent Slack config\n{\n  \"requireMention\": true\n}\n</code></pre> <p>Then restart: <code>openclaw gateway restart</code></p>"},{"location":"engineering/troubleshooting/#thread-replies-ignored-bug-24816","title":"Thread replies ignored (bug #24816)","text":"<p>Known bug: openclaw/openclaw#24816</p> <p>Thread replies in Slack carry an implicit mention \u2014 the platform treats them as directed at the bot even without an explicit <code>@mention</code>. The gateway does not always recognize this implicit mention, causing the agent to skip thread replies.</p> <p>Workaround:</p> <ul> <li>Always use an explicit <code>@BotName</code> in thread replies when you need a response.</li> <li>Or set <code>requireMention: false</code> for agents that must respond in threads (accept the tradeoff of responding to all channel messages).</li> </ul>"},{"location":"engineering/troubleshooting/#bot-responds-in-dm-instead-of-thread","title":"Bot responds in DM instead of thread","text":"<p>Cause: Agent is using the <code>message</code> tool to send a reply instead of using the natural reply mechanism. The <code>message</code> tool sends a new message to a channel/DM rather than replying in-thread.</p> <p>Fix: Update the agent's instructions to use natural reply (just respond) for Slack messages. The <code>message</code> tool should only be used for proactive/outbound messages, not responses.</p>"},{"location":"engineering/troubleshooting/#slack-socket-disconnected","title":"Slack socket disconnected","text":"<p>Diagnose:</p> <pre><code>openclaw logs | grep -i \"socket\\|reconnect\\|disconnect\" | tail -20\n</code></pre> <p>Fix:</p> <pre><code># Gateway restart re-establishes all socket connections\nopenclaw gateway restart\n\n# Verify socket connected after restart\nopenclaw logs | grep -i \"socket\\|connected\" | tail -10\n</code></pre> <p>Tip</p> <p>If disconnects happen frequently, check Pi network stability and whether the Pi is sleeping/throttling. <code>uptime</code> and <code>dmesg | tail -20</code> can show intermittent issues.</p>"},{"location":"engineering/troubleshooting/#5-session-memory-issues","title":"5. Session &amp; Memory Issues","text":""},{"location":"engineering/troubleshooting/#agent-has-no-context-amnesia","title":"Agent has no context / amnesia","text":"Check Command Agent has <code>agentDir</code> set <code>openclaw agents show &lt;id&gt;</code> SOUL.md exists <code>ls ~/.openclaw/agents/&lt;id&gt;/SOUL.md</code> agentDir path is correct <code>cat ~/.openclaw/agents/&lt;id&gt;/SOUL.md</code> Session transcript exists <code>ls ~/.openclaw/agents/&lt;id&gt;/sessions/</code> <p>Fix:</p> <pre><code># Add workspace + agentDir to agent config in openclaw.json\n# Then restart\nopenclaw gateway restart\n</code></pre>"},{"location":"engineering/troubleshooting/#session-not-resetting-when-it-should","title":"Session not resetting when it should","text":"<p>Diagnose:</p> <pre><code># Check resetByType config for the agent\nopenclaw agents show &lt;agent-id&gt; | grep -A5 \"reset\"\n</code></pre> <p>Common <code>resetByType</code> values:</p> Value Behavior <code>\"idle\"</code> Resets after idle timeout (default 24h for threads) <code>\"always\"</code> New session every message <code>\"never\"</code> Single persistent session <code>\"thread\"</code> One session per Slack thread <p>Fix by updating the agent's <code>resetByType</code> in <code>openclaw.json</code> and restarting.</p>"},{"location":"engineering/troubleshooting/#thread-session-expired-unexpectedly","title":"Thread session expired unexpectedly","text":"<p>Cause: 24-hour idle timeout. The thread went quiet for &gt;24h, session was cleared.</p> <p>Fix: Just <code>@mention</code> the agent in the thread again \u2014 a new session starts. The agent won't have memory of the previous thread unless session transcripts are loaded in the prompt.</p>"},{"location":"engineering/troubleshooting/#6-cron-jobs","title":"6. Cron Jobs","text":""},{"location":"engineering/troubleshooting/#job-not-firing","title":"Job not firing","text":"<p>Diagnose:</p> <pre><code># List all cron jobs with status\nopenclaw cron list\n\n# Look for: enabled, nextRun, lastRun, lastError\nopenclaw cron list | python3 -m json.tool\n</code></pre> Field to check Expected Problem <code>enabled</code> <code>true</code> <code>false</code> \u2192 job is paused <code>nextRun</code> Near-future timestamp Far future or null \u2192 schedule issue <code>lastRun</code> Recent timestamp Never ran \u2192 first-time config issue <code>lastError</code> null / empty Has value \u2192 job is erroring out <p>Fix:</p> <pre><code># Enable a disabled job\nopenclaw cron enable &lt;job-id&gt;\n\n# Trigger a job manually to test\nopenclaw cron run &lt;job-id&gt;\n\n# Check logs after manual run\nopenclaw logs | grep &lt;job-id&gt; | tail -20\n</code></pre>"},{"location":"engineering/troubleshooting/#job-erroring","title":"Job erroring","text":"<p>Diagnose:</p> <pre><code># Get last error\nopenclaw cron list | python3 -c \"\nimport json, sys\njobs = json.load(sys.stdin)\nfor j in jobs:\n    if j.get('lastError'):\n        print(j['id'], ':', j['lastError'])\n\"\n</code></pre> <p>Common causes:</p> Error Cause Fix <code>tool not found</code> Agent missing a required tool Add tool to agent config <code>timeout</code> Job taking longer than allowed Increase timeout in cron config <code>API error</code> / <code>401</code> Expired token Refresh token in <code>credentials/</code> <code>ENOENT</code> / file missing Script path wrong Check <code>command</code> field in cron config"},{"location":"engineering/troubleshooting/#jobs-lost-after-restart","title":"Jobs lost after restart","text":"<p>Info</p> <p>Cron state persists in the gateway store (<code>~/.openclaw/store</code>). Jobs are not lost on normal restart.</p> <p>If jobs disappeared: <pre><code># Check if store was wiped\nls -la ~/.openclaw/store/\n\n# Check gateway logs at startup for cron init\nopenclaw logs | grep -i \"cron\" | head -20\n</code></pre></p> <p>If the store was wiped (or you wiped it manually), cron jobs need to be re-registered.</p>"},{"location":"engineering/troubleshooting/#7-pi-resource-issues","title":"7. Pi Resource Issues","text":""},{"location":"engineering/troubleshooting/#oom-kills","title":"OOM kills","text":"<p>Symptom: Processes or the gateway die unexpectedly, especially during heavy use.</p> <pre><code># Confirm OOM kills\ndmesg | grep -i oom | tail -10\n\n# Current memory state\nfree -h\n\n# What's eating memory?\nps aux --sort=-%mem | head -15\n</code></pre> <p>Pi memory is limited</p> <p>The Pi 4 has 4\u20138GB RAM but multiple concurrent agent runs + <code>gh</code> CLI + Node.js processes can hit limits fast. If you're running &gt;3 agents concurrently, watch memory closely.</p> <p>Fix:</p> <pre><code># Kill memory hogs\nkill &lt;pid&gt;\n\n# Check if gh CLI is orphaned\nps aux | grep gh\nkill $(pgrep -f \"gh \")\n\n# Restart gateway after clearing\nopenclaw gateway restart\n</code></pre>"},{"location":"engineering/troubleshooting/#disk-full","title":"Disk full","text":"<pre><code># Check disk usage\ndf -h\n\n# Find what's eating space\ndu -sh ~/.openclaw/agents/*/sessions/ | sort -h | tail -10\ndu -sh /tmp/openclaw/ 2&gt;/dev/null\n\n# Clean old session transcripts (keep last 30 days)\nfind ~/.openclaw/agents -name \"*.jsonl\" -mtime +30 -delete\n\n# Clean old logs\nfind /tmp/openclaw/ -name \"*.log\" -mtime +7 -delete\n</code></pre> <p>Don't delete active session files</p> <p>Only clean sessions older than your retention window. Active sessions are in <code>sessions/</code> with recent timestamps.</p>"},{"location":"engineering/troubleshooting/#high-cpu","title":"High CPU","text":"<pre><code># Snapshot of top processes\ntop -b -n1 | head -20\n\n# Specifically check for Node (gateway) and Python (agent scripts)\nps aux --sort=-%cpu | grep -E \"node|python\" | head -10\n</code></pre> <p>Cause: Usually multiple agent runs in parallel. Each active session with a model call holds CPU.</p> <p>Fix:</p> <pre><code># Kill stuck sessions to free CPU\nopenclaw sessions list\nopenclaw sessions kill &lt;session-id&gt;\n\n# Or restart gateway to clear everything\nopenclaw gateway restart\n</code></pre>"},{"location":"engineering/troubleshooting/#8-common-config-mistakes","title":"8. Common Config Mistakes","text":"Mistake Symptom Fix Missing <code>workspace</code> on agent Agent can't find files, may error on tool calls Add <code>\"workspace\": \"/home/dobby/.openclaw/workspace\"</code> to agent config Missing <code>agentDir</code> on agent Amnesia on session reset Add <code>\"agentDir\": \"agents/&lt;name&gt;\"</code> to agent config <code>replyToMode: \"off\"</code> Agent replies in new messages, not threads (Slack) Set <code>\"replyToMode\": \"thread\"</code> Wrong calendar ID Events not appearing in agent responses Get correct ID from Google Calendar settings \u2192 copy the calendar ID Expired OAuth token API calls fail with 401/403 Refresh token in <code>~/.openclaw/credentials/</code> <code>requireMention: false</code> on multiple agents All bots respond to everything Set <code>requireMention: true</code> on agents that should only respond when @-mentioned Bad cron schedule expression Job never fires or fires constantly Validate cron expression at crontab.guru <pre><code># After any config change to openclaw.json, validate JSON first:\npython3 -c \"import json; json.load(open('$HOME/.openclaw/openclaw.json'))\" &amp;&amp; echo \"JSON valid\"\n\n# Then restart\nopenclaw gateway restart\n</code></pre>"},{"location":"engineering/troubleshooting/#9-log-locations-how-to-read-them","title":"9. Log Locations &amp; How to Read Them","text":""},{"location":"engineering/troubleshooting/#file-locations","title":"File locations","text":"Log type Location Gateway logs <code>/tmp/openclaw/openclaw-YYYY-MM-DD.log</code> Agent session transcripts <code>~/.openclaw/agents/&lt;id&gt;/sessions/*.jsonl</code> Cron logs Inside gateway logs \u2014 grep for <code>\"cron\"</code> <pre><code># Today's gateway log\ncat /tmp/openclaw/openclaw-$(date +%Y-%m-%d).log | tail -100\n\n# All logs, most recent first\nls -lt /tmp/openclaw/*.log\n\n# Grep for errors across all logs\ngrep -h \"ERROR\\|FATAL\" /tmp/openclaw/*.log | tail -30\n\n# Grep for a specific agent\ngrep -h \"&lt;agent-id&gt;\" /tmp/openclaw/*.log | tail -30\n</code></pre>"},{"location":"engineering/troubleshooting/#parsing-json-logs","title":"Parsing JSON logs","text":"<p>Gateway logs are newline-delimited JSON. Use Python to extract fields:</p> <pre><code># Extract just the message field from recent errors\ntail -200 /tmp/openclaw/openclaw-$(date +%Y-%m-%d).log | python3 -c \"\nimport sys, json\nfor line in sys.stdin:\n    try:\n        obj = json.loads(line)\n        if obj.get('level') in ('error', 'fatal'):\n            print(obj.get('time', ''), obj.get('msg', ''), obj.get('error', ''))\n    except:\n        pass\n\"\n\n# Show all fields for lines matching a pattern\ngrep \"session\" /tmp/openclaw/openclaw-$(date +%Y-%m-%d).log | python3 -c \"\nimport sys, json\nfor line in sys.stdin:\n    try:\n        print(json.dumps(json.loads(line), indent=2))\n    except:\n        print(line, end='')\n\" | head -100\n</code></pre>"},{"location":"engineering/troubleshooting/#reading-session-transcripts","title":"Reading session transcripts","text":"<pre><code># List sessions for an agent\nls -lt ~/.openclaw/agents/&lt;agent-id&gt;/sessions/\n\n# Read a session (each line is a JSON turn)\ncat ~/.openclaw/agents/&lt;agent-id&gt;/sessions/&lt;session-id&gt;.jsonl | python3 -c \"\nimport sys, json\nfor line in sys.stdin:\n    obj = json.loads(line)\n    role = obj.get('role', '?')\n    content = obj.get('content', '')\n    if isinstance(content, list):\n        content = ' '.join(c.get('text', '') for c in content if isinstance(c, dict))\n    print(f'[{role}] {str(content)[:200]}')\n\"\n</code></pre>"},{"location":"engineering/troubleshooting/#10-emergency-recovery","title":"10. Emergency Recovery","text":""},{"location":"engineering/troubleshooting/#full-gateway-reset","title":"Full gateway reset","text":"<pre><code>openclaw gateway stop &amp;&amp; sleep 2 &amp;&amp; openclaw gateway start\n\n# Verify it's up\nopenclaw gateway status\nopenclaw logs | tail -20\n</code></pre>"},{"location":"engineering/troubleshooting/#config-backup-rollback","title":"Config backup &amp; rollback","text":"<p>Always back up before editing <code>openclaw.json</code></p> <pre><code>cp ~/.openclaw/openclaw.json ~/.openclaw/openclaw.json.bak.$(date +%Y%m%d-%H%M%S)\n</code></pre> <pre><code># Back up current config\ncp ~/.openclaw/openclaw.json ~/.openclaw/openclaw.json.bak.$(date +%Y%m%d-%H%M%S)\n\n# List backups\nls -lt ~/.openclaw/openclaw.json.bak.*\n\n# Roll back to a specific backup\ncp ~/.openclaw/openclaw.json.bak.20260223-140000 ~/.openclaw/openclaw.json\n\n# Validate before restarting\npython3 -c \"import json; json.load(open('$HOME/.openclaw/openclaw.json'))\" &amp;&amp; echo \"JSON valid\"\n\n# Restart\nopenclaw gateway restart\n</code></pre>"},{"location":"engineering/troubleshooting/#gateway-store-reset-last-resort","title":"Gateway store reset (last resort)","text":"<p>This wipes cron state and persisted session data</p> <p>Only do this if the gateway refuses to start and you've ruled out config/port issues.</p> <pre><code># Stop gateway first\nopenclaw gateway stop\n\n# Back up the store\ncp -r ~/.openclaw/store ~/.openclaw/store.bak.$(date +%Y%m%d-%H%M%S)\n\n# Wipe the store\nrm -rf ~/.openclaw/store\n\n# Start fresh\nopenclaw gateway start\n\n# Re-register any cron jobs that were lost\n</code></pre>"},{"location":"engineering/troubleshooting/#quick-reference-most-common-fixes","title":"Quick reference: most common fixes","text":"Problem One-liner fix Gateway won't start \u2014 port conflict <code>kill $(lsof -t -i :5050) &amp;&amp; openclaw gateway start</code> Config change not reflected <code>openclaw gateway restart</code> Stuck session <code>openclaw sessions kill &lt;id&gt;</code> Agent amnesia Check <code>agentDir</code> in config, <code>openclaw gateway restart</code> Cron job disabled <code>openclaw cron enable &lt;id&gt;</code> Socket disconnected <code>openclaw gateway restart</code> Disk full <code>find ~/.openclaw/agents -name \"*.jsonl\" -mtime +30 -delete</code> OOM crash <code>openclaw gateway restart</code> + reduce concurrent agents Roll back config <code>cp ~/.openclaw/openclaw.json.bak.&lt;ts&gt; ~/.openclaw/openclaw.json &amp;&amp; openclaw gateway restart</code>"},{"location":"platform/","title":"Platform","text":"<p>Documentation for the JourneyLoop platform \u2014 what it is, how it's modeled, and the frameworks that drive its AI.</p> <p>Start here</p> <p>This section covers the product and domain layer: concepts that underpin everything else. If you're building a feature, integrating a new system, or configuring an agent, start here to understand the model you're working with.</p> <ul> <li> <p> Overview</p> <p>The full platform reference: what JourneyLoop is, who it serves, the core data model (coaches, clients, sessions, goals, milestones, utterances), how sessions flow through the system, and what data is available via the companion API.</p> <p>Read this first.</p> <p> Platform Overview</p> </li> <li> <p> SHIFT Framework</p> <p>JourneyLoop's proprietary coaching quality model. Five principles \u2014 Surface Emotion, Hand Back Ownership, Illuminate Contradictions, Find the Pattern, Turn Insight into Action \u2014 with patterns, anti-patterns, and evidence-backed rationale.</p> <p>The AI session analysis is built entirely on this framework.</p> <p> SHIFT Framework</p> </li> </ul>"},{"location":"platform/overview/","title":"JourneyLoop \u2014 Platform Reference","text":""},{"location":"platform/overview/#what-is-journeyloop","title":"What is JourneyLoop?","text":"<p>JourneyLoop is an AI-powered coaching companion platform for independent coaches. Its tagline: \"You hold space for everyone. But who holds space for you?\"</p> <p>Core premise</p> <p>Coaching is an isolated profession. JourneyLoop fixes that by acting as a companion to the coach \u2014 capturing every session, surfacing insights, reflecting growth, and preparing coaches for what's next. Coaches don't manually take notes or review transcripts. JourneyLoop handles that automatically.</p> <p>The product does three things:</p> <ul> <li> <p> Record &amp; Transcribe</p> <p>Coaching sessions captured automatically via a Recall.ai bot joining Zoom, Meet, or Teams.</p> </li> <li> <p> Analyze Quality</p> <p>Transcripts analyzed using the SHIFT framework \u2014 giving coaches structured feedback on their coaching quality.</p> </li> <li> <p> Track Progress</p> <p>Client progress tracked across goals, milestones, and behavior patterns over time \u2014 with no manual input.</p> </li> </ul>"},{"location":"platform/overview/#core-data-model","title":"Core Data Model","text":""},{"location":"platform/overview/#coach-coachingprofile-authuser","title":"Coach (<code>CoachingProfile</code> \u2192 <code>auth.User</code>)","text":"<p>The primary user. Has a name, business name, coaching niche, and description. Owns all clients and sessions.</p>"},{"location":"platform/overview/#client-coachingclient","title":"Client (<code>CoachingClient</code>)","text":"<p>Belongs to one coach.</p> Field Description <code>name</code>, <code>email</code> Identity <code>total_sessions</code> Sessions in the coaching package (e.g., 6 or 12) <code>actual_completed_sessions</code> Dynamic count (date \u2264 today, type = regular) <code>sessions</code> \u2192 <code>CoachingSession</code> objects <code>progress_goals</code> \u2192 <code>CoachingGoal</code> objects <code>milestones</code> \u2192 <code>CoachingMilestone</code> objects <code>has_consented</code> Client must consent before AI can process their transcripts <p>Note</p> <p>Clients may optionally have portal access via a linked <code>auth.User</code>.</p>"},{"location":"platform/overview/#session-coachingsession","title":"Session (<code>CoachingSession</code>)","text":"<p>A single coaching meeting.</p> Field Description <code>client</code> FK to <code>CoachingClient</code> <code>title</code>, <code>date</code>, <code>session_type</code> <code>regular</code> or <code>intake</code> \u2014 intake doesn't count toward package total <code>transcript</code> Full text (deferred by default for performance; use <code>all_fields</code> manager when needed) <code>transcript_json</code> Raw JSON from Recall.ai with timestamps <code>meeting_url</code>, <code>recall_bot_id</code>, <code>recall_bot_status</code> Recall.ai recording integration <code>progress_extracted</code> Whether AI has processed this session <code>is_completed</code> Property: <code>date &lt;= today</code>"},{"location":"platform/overview/#utterance-sessionutterance","title":"Utterance (<code>SessionUtterance</code>)","text":"<p>Individual speech segment from a transcript.</p> Field Description <code>speaker_type</code> <code>coach</code> or <code>client</code> <code>text_clean</code> Cleaned text <code>sequence_number</code> 1-based ordering <code>timestamp_min</code> / <code>timestamp_sec</code> Position in session"},{"location":"platform/overview/#the-shift-framework","title":"The SHIFT Framework","text":"<p>About SHIFT</p> <p>SHIFT is JourneyLoop's proprietary coaching quality model, grounded in ICF competencies and evidence-based coaching research. After each session, AI analyzes the transcript against 5 principles, identifying moments where the coach applied them well (Excellence Signals) or missed an opportunity (Growth Opportunities).</p> <p>SHIFT = S \u00b7 H \u00b7 I \u00b7 F \u00b7 T</p>  S \u2014 Surface Emotion H \u2014 Hand Back Ownership I \u2014 Illuminate Contradictions F \u2014 Find the Pattern T \u2014 Turn Insight into Action <p>Notice, name, and validate client emotions when they arise.</p> <p>Patterns \u2014 what good looks like:</p> Pattern Description Label the Feeling Coach reflects client's emotional language (\"That overwhelm sounds really heavy for you.\") Ask About Emotion Coach directly inquires about feelings (\"What feelings are coming up as you say that?\") Affective Mirroring Coach's tone matches client's emotional state <p>Anti-patterns \u2014 missed opportunities:</p> Anti-pattern Description Task-Switch after Emotion Pivoting to tasks right after emotional disclosure Emotion Avoidance Ignoring or sidestepping emotional cues Affect-Free Paraphrase Paraphrasing content without reflecting the emotion <p>Return agency to the client. Let them define direction and next steps.</p> <p>Patterns:</p> Pattern Description Invite Decisions Coach asks client to define their own solutions Agency Language Framing that emphasizes the client's choice (\"It's your choice which step you take first.\") Curiosity over Advice Using inquiry instead of giving answers <p>Anti-patterns:</p> Anti-pattern Description Preemptive Advice Offering solutions before the client has a chance to find their own Goal Takeover Coach reshapes or restates the client's goals with their own agenda Directed Solutions Dictating what the client should do <p>Spot and reflect inconsistencies, limiting beliefs, or avoidance in the client's language.</p> <p>Patterns:</p> Pattern Description Name the Tension Coach reflects contradictions (\"You say you want to take risks, yet uncertainty feels intolerable \u2014 how do those fit together?\") Values-Behavior Check Highlighting misalignment between stated values and actions Invite the Disowned Exploring topics the client is avoiding <p>Anti-patterns:</p> Anti-pattern Description Contradiction Blindness Ignoring clear inconsistencies in the client's narrative Comfort Detour Sidestepping difficult or uncomfortable material Reassure Instead of Explore Soothing away contradictions rather than exploring them <p>Name meaningful themes or behavioral loops visible within (and across) the session.</p> <p>Patterns:</p> Pattern Description Theme Detection Identifying a recurring theme in the client's language Name Core Driver Identifying a deeper belief or value driving behavior Reframe to Meta Lifting the narrative to a higher pattern-based level <p>Anti-patterns:</p> Anti-pattern Description Surface Parroting Repeating client words without deeper synthesis Theme Avoidance Ignoring recurring signals Reactive Only Responding moment-to-moment without connecting the dots <p>Help the client translate reflection into clear, specific, committed next steps.</p> <p>Patterns:</p> Pattern Description Elicit Concrete Action Asking the client to define their own next steps (\"What's one specific action you'll take this week?\") Make It Measurable Encouraging time-bound, specific commitments Reflect Decisions Made Consolidating commitments voiced during the session <p>Anti-patterns:</p> Anti-pattern Description No Next Step Session ends without any explicit action Insight-Only Closure Celebrating insight but skipping action planning Coach-Defined Action Prescribing steps instead of eliciting them"},{"location":"platform/overview/#ai-generated-session-content","title":"AI-Generated Session Content","text":"<p>When a transcript is uploaded, a <code>SessionContentRequest</code> processes four things asynchronously:</p> <pre><code>graph TD\n    T[Transcript uploaded] --&gt; SCR[SessionContentRequest]\n    SCR --&gt; A[Session Analysis&lt;br/&gt;CoachingSessionAnalysis]\n    SCR --&gt; B[SHIFT Insights&lt;br/&gt;GrowthOpportunity + ExcellenceSignal]\n    SCR --&gt; C[Progress&lt;br/&gt;SessionObservation objects]\n    SCR --&gt; D[Behavior Loops&lt;br/&gt;ClientLoop patterns]</code></pre> Output Model Description Session Analysis <code>CoachingSessionAnalysis</code> Overall session summary, themes, key takeaways SHIFT Insights <code>GrowthOpportunity</code> + <code>ExcellenceSignal</code> Linked to specific utterances, with coach feedback and better examples Progress <code>SessionObservation</code> Extracted from utterances, linked to goals/milestones with numeric delta impact Behavior Loops <code>ClientLoop</code> Recurring trigger-response-consequence patterns across sessions"},{"location":"platform/overview/#progress-tracking","title":"Progress Tracking","text":"Goals Milestones Observations Behavior Loops <p>Long-running objectives via <code>CoachingGoal</code>.</p> <ul> <li><code>slug</code> \u2014 unique per client, used for AI reference</li> <li><code>title</code>, <code>status</code> \u2014 <code>active</code> / <code>paused</code> / <code>complete</code></li> <li>Progress accumulates via <code>ObservationGoal</code> delta links (\u22120.10 to +0.10 per observation)</li> </ul> <p>Date-driven events via <code>CoachingMilestone</code>.</p> <ul> <li><code>target_date</code>, <code>status</code> \u2014 <code>upcoming</code> / <code>completed</code> / <code>missed</code></li> <li>Example: \"Sales presentation on March 15th\"</li> </ul> <p>AI-extracted client moments via <code>SessionObservation</code>.</p> <ul> <li><code>stance</code> \u2014 <code>struggle</code> / <code>intent</code> / <code>plan</code> / <code>reflection</code> / <code>outcome</code></li> <li><code>valence</code> \u2014 \u22121.0 to 1.0</li> <li><code>intensity</code>, <code>certainty</code> scores</li> <li>Linked to goals and milestones with delta impacts</li> </ul> <p>Cross-session patterns via <code>ClientLoop</code>.</p> <ul> <li>Structure: <code>trigger</code> \u2192 <code>response</code> \u2192 <code>consequence</code></li> <li>Status: <code>emerging</code> / <code>active</code> / <code>evolving</code> / <code>resolved</code></li> </ul>"},{"location":"platform/overview/#companion-api","title":"Companion API","text":"<p>Authentication</p> <p>Bearer token auth via <code>CompanionAPIKeyAuthentication</code>. Scoped to the coach who owns the key. Base path: <code>/api/companion/v1/</code></p> <p>Clients</p> Method Path Description <code>GET</code> <code>/clients/</code> List clients (id, name, email) <code>GET</code> <code>/clients/&lt;id&gt;/</code> Client detail with goals and milestones <code>GET</code> <code>/clients/search/?q=</code> Search clients by name <code>GET</code> <code>/clients/&lt;id&gt;/sessions/</code> All sessions for a client <code>GET</code> <code>/clients/&lt;id&gt;/goals/</code> List goals <code>POST</code> <code>/clients/&lt;id&gt;/goals/</code> Create a goal <code>PATCH</code> <code>/clients/&lt;id&gt;/goals/&lt;goal_id&gt;/</code> Update goal title or status <code>DELETE</code> <code>/clients/&lt;id&gt;/goals/&lt;goal_id&gt;/</code> Delete a goal <p>Sessions</p> Method Path Description <code>GET</code> <code>/sessions/upcoming/</code> Upcoming sessions (next 7 days) <code>GET</code> <code>/sessions/recent/?limit=N</code> Recent past sessions (default 10) <code>GET</code> <code>/sessions/&lt;id&gt;/</code> Session detail <code>GET</code> <code>/sessions/&lt;id&gt;/transcript/</code> Raw transcript text <p>Profile</p> Method Path Description <code>PATCH</code> <code>/profile/</code> Update companion profile (e.g., set name)"},{"location":"platform/overview/#key-integrations","title":"Key Integrations","text":"<ul> <li> <p> Recall.ai</p> <p>Recording bot that joins video calls (Zoom, Meet, Teams) and captures live transcripts.</p> </li> <li> <p> Google Calendar</p> <p>Auto-creates sessions from calendar events.</p> </li> <li> <p> Stripe</p> <p>Coach subscription billing \u2014 Starter free, paid tiers for more clients.</p> </li> <li> <p> Client Portal</p> <p>Clients can log in, view session takeaways, and track their own progress.</p> </li> </ul>"}]}